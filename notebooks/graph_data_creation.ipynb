{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spektral.data import Dataset, Graph\n",
    "import pickle\n",
    "from importlib import reload\n",
    "import dataset\n",
    "reload(dataset)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('mode.chained_assignment', None) # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load combined data\n",
    "df_raw = pd.read_csv('../data/combined.csv')\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Load hero feature data\n",
    "df_features = pd.read_csv('../data/features.csv')\n",
    "df_features = df_features.set_index('hero_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Data Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DotaV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate DotaV1 dataset for 50000 matches at a time\n",
    "count = 0\n",
    "total = len(df)\n",
    "step = 50000\n",
    "\n",
    "for i in range(0,int(np.ceil(total/step))):\n",
    "    start = i*step\n",
    "    end = start+step if (start+step)<total else total\n",
    "    df_current = df.iloc[start:end]\n",
    "    print(f'Start: {start} End: {end-1}')\n",
    "    graphs_current = dataset.DotaV1(df_current, df_features)\n",
    "    \n",
    "    filehandler = open(f'../data/graphs_v1/graphs_v1_{start}-{end-1}.pkl','wb')\n",
    "    pickle.dump(graphs_current, filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DotaV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate DotaV2 dataset for 50000 matches at a time\n",
    "count = 0\n",
    "total = len(df)\n",
    "step = 50000\n",
    "\n",
    "for i in range(0,int(np.ceil(total/step))):\n",
    "    start = i*step\n",
    "    end = start+step if (start+step)<total else total\n",
    "    df_current = df.iloc[start:end]\n",
    "    print(f'Start: {start} End: {end-1}')\n",
    "    graphs_current = dataset.DotaV2(df_current, df_features)\n",
    "    \n",
    "    filehandler = open(f'../data/graphs_v2/graphs_v2_{start}-{end-1}.pkl','wb')\n",
    "    pickle.dump(graphs_current, filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DotaV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DotaV1 graphs\n",
    "dir = '../data/graphs_v1/'\n",
    "count = 0\n",
    "total = len(df)\n",
    "step = 50000\n",
    "\n",
    "for i in range(0,int(np.ceil(total/step))):\n",
    "    start = i*step\n",
    "    end = start+step-1 if (start+step)<total else total-1\n",
    "    path = dir+f'graphs_v1_{start}-{end}.pkl'\n",
    "    print(path)\n",
    "    file = open(path,'rb')\n",
    "    if i==0:\n",
    "        graphs = pickle.load(file)\n",
    "    else:\n",
    "        graphs = graphs + pickle.load(file)\n",
    "\n",
    "print('DotaV1 graph dataset loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMax Scaler model to normalise features from 0-1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_features.iloc[:,3:].to_numpy())\n",
    "\n",
    "# Loop through each graph and scale feature matrix and drop attack_backswing feature\n",
    "# print('Scaling graph dataset feature matrices:')   \n",
    "for i in range(0,len(graphs)):\n",
    "    if(i%100000==0):\n",
    "        print(i)\n",
    "    graphs[i].x = scaler.transform(graphs[i].x) # scale feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scaled graphs\n",
    "for i in range(0,int(np.ceil(total/step))):\n",
    "    start = i*step\n",
    "    end = start+step if (start+step)<total else total\n",
    "    print(f'Start: {start} End: {end-1}')\n",
    "    graphs_current = graphs[2*start:2*end] #2* because it needs 0-100000 to include radiant 50000 and dire 50000\n",
    "    \n",
    "    filehandler = open(f'../data/graphs_v1_scaled/graphs_v1_scaled_{start}-{end-1}.pkl','wb')\n",
    "    pickle.dump(graphs_current, filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DotaV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DotaV2 graphs\n",
    "dir = '../data/graphs_v2/'\n",
    "count = 0\n",
    "total = len(df)\n",
    "step = 50000\n",
    "\n",
    "for i in range(0,int(np.ceil(total/step))):\n",
    "    start = i*step\n",
    "    end = start+step-1 if (start+step)<total else total-1\n",
    "    path = dir+f'graphs_v2_{start}-{end}.pkl'\n",
    "    print(path)\n",
    "    file = open(path,'rb')\n",
    "    if i==0:\n",
    "        graphs = pickle.load(file)\n",
    "    else:\n",
    "        graphs = graphs + pickle.load(file)\n",
    "\n",
    "print('DotaV2 graph dataset loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMax Scaler model to normalise features from 0-1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_features.iloc[:,3:].to_numpy())\n",
    "\n",
    "# Loop through each graph and scale feature matrix and drop attack_backswing feature\n",
    "# print('Scaling graph dataset feature matrices:')   \n",
    "for i in range(0,len(graphs)):\n",
    "    if(i%100000==0):\n",
    "        print(i)\n",
    "    graphs[i].x = scaler.transform(graphs[i].x) # scale feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scaled graphs\n",
    "for i in range(0,int(np.ceil(total/step))):\n",
    "    start = i*step\n",
    "    end = start+step if (start+step)<total else total\n",
    "    print(f'Start: {start} End: {end-1}')\n",
    "    graphs_current = graphs[start:end]\n",
    "    \n",
    "    filehandler = open(f'../data/graphs_v2_scaled/graphs_v2_scaled_{start}-{end-1}.pkl','wb')\n",
    "    pickle.dump(graphs_current, filehandler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dotaprediction-eZ2WDOkz')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ebde562489c4e4788da5bb29c9d71313b7139998376f0f1594e5d84eb8d638a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
