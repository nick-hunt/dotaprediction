{"cells":[{"cell_type":"markdown","metadata":{"id":"dU1qz8WsuIH-"},"source":["# Data Acquisition"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from datetime import datetime\n","import time\n","import opendota\n","import pandas as pd\n","import numpy as np\n","import json\n","import os"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":538522,"status":"ok","timestamp":1646518253998,"user":{"displayName":"Nicholas Hunt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJ1rse5O5pkiuRIPQxPkWElPUdP1lZdwhcSoeoSQ=s64","userId":"08231052150920003948"},"user_tz":0},"id":"au5b_QR8uOQi","outputId":"fb3c7fb3-bfc5-4c88-8d5d-a872e3798c3b"},"outputs":[],"source":["def get_match_list(datetime_start_unix, dateime_end_unix):\n","  '''Queries the OpenDota \"public_matches\" table between two datetimes using PostgreSQL and saves a csv called matches_yyyymmdd_hhmmss.csv'''\n","  client = opendota.OpenDota()\n","\n","  result_size = 500000\n","  start_time = datetime_start_unix\n","  i=0\n","\n","  # Divides the requests into 500000 chunks, due to size limitations when querying the OpenDota API\n","  while result_size == 500000:\n","    i=i+1\n","    output_cur = client.explorer(f'SELECT * FROM public_matches where start_time > {start_time} AND start_time < {dateime_end_unix} LIMIT 500000')\n","    start_time = output_cur[-1]['start_time']\n","    result_size = len(output_cur)\n","    df_output_cur = pd.DataFrame(output_cur)\n","    \n","    if i == 1:\n","      df_output = df_output_cur\n","    else:\n","      df_output = pd.concat([df_output, df_output_cur], axis=0)\n","\n","    print('Loop ' + str(i) +' - Size ' + str(len(df_output))) \n","  \n","  return df_output"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Loop 1 - Size 500000\n","Loop 2 - Size 1000000\n","Loop 3 - Size 1500000\n","Loop 4 - Size 2000000\n","Loop 5 - Size 2500000\n","Loop 6 - Size 3000000\n","Loop 7 - Size 3500000\n","Loop 8 - Size 4000000\n","Loop 9 - Size 4500000\n","Loop 10 - Size 5000000\n","Loop 11 - Size 5500000\n","Loop 12 - Size 5600752\n"]}],"source":["# Generate match list\n","# Dates for fixed hero time:\n","# Marci added 28/10/2021, so 29/10/2021 = 1635462000\n","# Primal Beast added 23/02/2022, so 22/02/2022 = 1645488000\n","# Above time window is ~4 months\n","\n","# Dates for Primal Beast added\n","# Primal Beast added 23/02/2022, so 24/02/2022 = 1645660800\n","# Up to 2 months after, so 24/04/2022 = 1650758400\n","\n","### Sometimes the first few runs do not work due to no response for the OpenDota API - keep trying and it will eventually work\n","df_match_list = get_match_list(1645660800,1650758400)\n","now = datetime.now()\n","df_match_list.to_csv(f'match_list_{now.year:04d}{now.month:02d}{now.day:02d}_{now.hour:02d}{now.minute:02d}{now.second:02d}.csv')"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def download_match_heroes(match_ids):\n","    '''Uses the PyOpenDota function \"get_match\" to return match information about each \"match_id\" in iterable argument \"matches\"\n","    Saves heroes picked/banned for each match_id in a json file called match-id.json'''\n","    client = opendota.OpenDota()\n","    total = len(match_ids)\n","    count = 0\n","    for match_id in match_ids:\n","        count += 1\n","        print(str(count) + '/' + str(total))\n","        try:\n","            match = client.get_match(match_id)\n","            matchjson = json.dumps(match)\n","            f = open(f'match_jsons\\\\{match_id}.json','w')\n","            f.write(matchjson)\n","            f.close()\n","        except:\n","            pass\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Fetch selected heroes for each match_id\n","matches = pd.read_csv('match_list_.csv') # replace argument with match_list .csv file\n","download_match_heroes(matches['match_id'])"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def check_hero_picks(picks_bans):\n","    '''Function takes a list of pick+ban dictionaries and returns boolean with whether there were a total of 10 picks and 5 on each team\n","    True: 10 total picks, 5 team0 picks, 5 team1 picks, picks were in first ten records in list\n","    False: otherwise'''\n","\n","    picks = [np.nan]*10\n","    valid = False\n","    picks_total = 0\n","    picks_team0 = 0\n","    picks_team1 = 0\n","    count=0\n","    first_ten = True\n","    for pickban in picks_bans:\n","        if pickban['is_pick']==True:\n","            picks_total+=1\n","            if count>9:\n","                first_ten = False\n","            if pickban['team']==0:\n","                if picks_team0<5:\n","                    picks[picks_team0] = pickban['hero_id']\n","                picks_team0+=1\n","            elif pickban['team']==1:\n","                if picks_team1<5:\n","                    picks[picks_team1+5] = pickban['hero_id']\n","                picks_team1+=1\n","        count+=1\n","\n","    if (picks_total==10) & (picks_team0==5) & (picks_team1==5) & first_ten:\n","        valid = True\n","    \n","    output = {'valid': valid, 'picks': picks}\n","\n","    return output"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def compile_match_heroes():\n","    matches = pd.read_csv('match_list_.csv') # replace argument with match list csv\n","    num_matches = len(matches)\n","    dir_match_jsons = 'match_jsons/'\n","    # Results df\n","    df_heroes = pd.DataFrame(columns=['match_id','hero0','hero1','hero2','hero3','hero4','hero5','hero6','hero7','hero8','hero9','heroes_valid'])\n","\n","    count = 0\n","    for idx, match in matches.iterrows():\n","        match_id = match['match_id']\n","        if match_id>6447015601:\n","            break\n","        # Try see if json for match exists\n","        try:\n","            picks_bans = json.load(open(f'{dir_match_jsons}{match_id}.json'))['picks_bans']\n","            picksbans_checked = check_hero_picks(picks_bans)\n","            df_heroes.loc[count,:] = [match_id] + picksbans_checked['picks'] + [picksbans_checked['valid']]\n","            \n","        # If no match json, include row of nans\n","        except:\n","            # print('exception')\n","            df_heroes.loc[count,:] = [match_id] + [np.nan]*10 + [False]\n","        count+=1\n","        print(f'{count}/{num_matches} - {match_id}')\n","\n","    now = datetime.now()        \n","    df_heroes.to_csv(f'match_heroes_{now.year:04d}{now.month:02d}{now.day:02d}_{now.hour:02d}{now.minute:02d}{now.second:02d}.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Compile jsons into updated \"matches\" table\n","compile_match_heroes()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# Merge matches and heroes datasets\n","df_match_list = pd.read_csv('match_list_.csv') # replace argument with match list csv\n","df_match_heroes = pd.read_csv('match_heroes_.csv') # replace argument with match hero csv\n","\n","df_match_merged = df_match_list.merge(df_match_heroes, on='match_id', how='left')\n","now = datetime.now()\n","df_match_merged.to_csv(f'match_merged_{now.year:04d}{now.month:02d}{now.day:02d}_{now.hour:02d}{now.minute:02d}{now.second:02d}.csv')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPaXT3XGSYvOAeYPT9J1BT3","collapsed_sections":[],"mount_file_id":"1CHzUcjAoTCeYv9xY7IzM5RAl-_M995sV","name":"project_data_extraction.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.4 ('dotaprediction-eZ2WDOkz')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"ebde562489c4e4788da5bb29c9d71313b7139998376f0f1594e5d84eb8d638a0"}}},"nbformat":4,"nbformat_minor":0}
