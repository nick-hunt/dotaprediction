{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spektral.data import Dataset, Graph, BatchLoader\n",
    "import dataset\n",
    "reload(dataset)\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from spektral.layers import GATConv, GCNConv, GlobalAvgPool, GlobalMaxPool, GlobalSumPool, GlobalAttentionPool\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graph dataset\n",
    "path = '../data/graphs_v1_scaled/graphs_v1_scaled_0-49999.pkl'\n",
    "file = open(path,'rb')\n",
    "graphs = pickle.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove attack_backswing feature\n",
    "for i in range(0,len(graphs)):\n",
    "    graphs[i].x = graphs[i].x[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,15,16,17,18,19]] # remove attack_backswing as a feature\n",
    "print('Attack backswing feature removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/valid/test split\n",
    "np.random.seed(10)\n",
    "idxs = np.random.permutation(len(graphs))\n",
    "split_va, split_te = int(0.64 * len(graphs)), int(0.8 * len(graphs)) #64% training, 16% validation, 20% test\n",
    "idx_tr, idx_va, idx_te = np.split(idxs, [split_va, split_te])\n",
    "data_tr = graphs[idx_tr]\n",
    "data_va = graphs[idx_va]\n",
    "data_te = graphs[idx_te]\n",
    "\n",
    "print(f'Training data: {np.round(len(data_tr)/len(graphs),2)*100}%')\n",
    "print(f'Validation data: {np.round(len(data_va)/len(graphs),2)*100}%')\n",
    "print(f'Test data: {np.round(len(data_te)/len(graphs),2)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "learning_rate = 0.001  # Learning rate\n",
    "epochs = 50  # Number of training epochs\n",
    "batch_size = 256  # Batch size\n",
    "\n",
    "# Data loaders\n",
    "loader_tr = BatchLoader(data_tr, batch_size=batch_size, epochs=epochs)\n",
    "loader_va = BatchLoader(data_va, batch_size=batch_size)\n",
    "loader_te = BatchLoader(data_te, batch_size=batch_size)\n",
    "\n",
    "# Build model\n",
    "class Net_sample(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(19, activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.dense = Dense(graphs.n_labels, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        x = self.conv1([x, a])\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x) \n",
    "        return x\n",
    "\n",
    "# Train model\n",
    "model_sample = Net_sample()\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "loss_fn = BinaryCrossentropy()\n",
    "model_sample.compile(optimizer=optimizer, loss=loss_fn, metrics=['binary_accuracy'])\n",
    "fit_log_sample = model_sample.fit(loader_tr.load(), steps_per_epoch=loader_tr.steps_per_epoch, epochs=epochs, validation_data=loader_va.load(), validation_steps=loader_va.steps_per_epoch)\n",
    "\n",
    "# Save training record\n",
    "epochs = list(range(1,len(fit_log_sample.history['binary_accuracy'])+1))\n",
    "training_accuracy = fit_log_sample.history['binary_accuracy']\n",
    "validation_accuracy = fit_log_sample.history['val_binary_accuracy']\n",
    "pd.DataFrame({'epoch': epochs, 'training_accuracy':training_accuracy, 'validation_accuracy':validation_accuracy}).to_csv('../models/fit_records/model_sample_accuracy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: save model\n",
    "model_sample.save(f'../models/model_sample.tf', save_format='tf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aead6205437b837a6f51f1a5578747fd76aee053b7788bc0930d4c5b4657d24d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
