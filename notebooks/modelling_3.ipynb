{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import dataset\n",
    "from importlib import reload\n",
    "reload(dataset)\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load combined data\n",
    "df = pd.read_csv('../data/combined.csv')\n",
    "\n",
    "# Load hero feature data\n",
    "df_features = pd.read_csv('../data/features.csv')\n",
    "df_features = df_features.set_index('hero_id')\n",
    "\n",
    "# Load standard filter\n",
    "df_filters = pd.read_csv('../models/filters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filt_idx(filt):\n",
    "    '''Returns indices of desired matches given a boolean array filter e.g. True, False, True returns [0,2]'''\n",
    "    # DotaV1 data handling (two graphs for every match: 0-49999 radiant, 0-49999 dire, 50000-99999 radiant, etc.)\n",
    "    step = 50000\n",
    "    filt_vals = []\n",
    "    for i in range(0,int(np.ceil(len(filt)/step))):\n",
    "        start = i*step\n",
    "        end = start+step\n",
    "        # Add filters for match range twice, as matches repeated every 50000\n",
    "        filt_vals = np.append(filt_vals, filt[start:end])\n",
    "        filt_vals = np.append(filt_vals, filt[start:end])\n",
    "\n",
    "    # Get indices of True values in filters\n",
    "    filt_idx = [i for i, x in enumerate(filt_vals) if x]\n",
    "    return filt_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph data already has the scaled features and match results\n",
    "# Load graph dataset 50000 matches at a time\n",
    "dir = '../data/graphs_v1_scaled/'\n",
    "count = 0\n",
    "total = len(df)\n",
    "step = 50000\n",
    "\n",
    "for i in range(0,int(np.ceil(total/step))):\n",
    "    start = i*step\n",
    "    end = start+step-1 if (start+step)<total else total-1\n",
    "    path = dir+f'graphs_v1_scaled_{start}-{end}.pkl'\n",
    "    print(path)\n",
    "    file = open(path,'rb')\n",
    "    if i==0:\n",
    "        graphs = pickle.load(file)\n",
    "    else:\n",
    "        graphs = graphs + pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X matrix (predictors) and y array (response) from graph data\n",
    "# Training\n",
    "X = np.empty([len(graphs), 20])\n",
    "y = np.empty(len(graphs))\n",
    "\n",
    "print('Converting graphs to X and y')\n",
    "for i, graph in enumerate(graphs):\n",
    "    if i%1000000==0:\n",
    "        print(i)\n",
    "    X[i,:] = np.mean(graphs[i].x,0)\n",
    "    y[i] = graphs[i].y\n",
    "\n",
    "print('Saving X and y numpy')\n",
    "with open('../data/standard_v1/X.npy', 'wb') as f:\n",
    "    np.save(f, X)\n",
    "with open('../data/standard_v1/y.npy', 'wb') as f:\n",
    "    np.save(f, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load X and y data\n",
    "with open('../data/standard_v1/X.npy', 'rb') as f:\n",
    "    X = np.load(f)\n",
    "with open('../data/standard_v1/y.npy', 'rb') as f:\n",
    "    y = np.load(f)\n",
    "\n",
    "# Filter data\n",
    "# Standard filter\n",
    "filt = get_filt_idx(df_filters['filt_std'])\n",
    "X_filt = X[filt]\n",
    "y_filt = y[filt]\n",
    "\n",
    "# Removed attack backswing feature\n",
    "X_filt = np.delete(X_filt,14,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 64.0%\n",
      "Validation data: 16.0%\n",
      "Test data: 20.0%\n"
     ]
    }
   ],
   "source": [
    "# Training/validation/test data split\n",
    "np.random.seed(10)\n",
    "idxs = np.random.permutation(len(y_filt))\n",
    "split_va, split_te = int(0.64 * len(y_filt)), int(0.8 * len(y_filt)) #64% training, 16% validation, 20% test\n",
    "idx_tr, idx_va, idx_te = np.split(idxs, [split_va, split_te])\n",
    "X_tr, X_va, X_te = X_filt[idx_tr], X_filt[idx_va], X_filt[idx_te]\n",
    "y_tr, y_va, y_te = y_filt[idx_tr], y_filt[idx_va], y_filt[idx_te]\n",
    "\n",
    "print(f'Training data: {np.round(len(y_tr)/len(y_filt),2)*100}%')\n",
    "print(f'Validation data: {np.round(len(y_va)/len(y_filt),2)*100}%')\n",
    "print(f'Test data: {np.round(len(y_te)/len(y_filt),2)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "regr = linear_model.LogisticRegression(penalty='l1',\n",
    "    solver='saga',  # or 'liblinear'\n",
    "    C=10000)\n",
    "regr = linear_model.LogisticRegression()\n",
    "regr.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 52.29%\n",
      "Validation Accuracy: 52.28%\n"
     ]
    }
   ],
   "source": [
    "y_pred_tr = regr.predict(X_tr)\n",
    "y_pred_va = regr.predict(X_va)\n",
    "print(f'Train Accuracy: {np.round(metrics.accuracy_score(y_tr, y_pred_tr)*100,2)}%')\n",
    "print(f'Validation Accuracy: {np.round(metrics.accuracy_score(y_va, y_pred_va)*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduced features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load X and y data\n",
    "with open('../data/standard_v1/X.npy', 'rb') as f:\n",
    "    X = np.load(f)\n",
    "with open('../data/standard_v1/y.npy', 'rb') as f:\n",
    "    y = np.load(f)\n",
    "\n",
    "# Filter data\n",
    "# Standard filter\n",
    "filt = get_filt_idx(df_filters['filt_std'])\n",
    "X_filt = X[filt]\n",
    "y_filt = y[filt]\n",
    "\n",
    "# Removed attack backswing feature\n",
    "X_filt = np.delete(X_filt,14,1)\n",
    "\n",
    "# Filter to reduced features\n",
    "X_filt = X_filt[:,[0,1,2,3,4,5,6,7,8,9,10,11,18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 64.0%\n",
      "Validation data: 16.0%\n",
      "Test data: 20.0%\n"
     ]
    }
   ],
   "source": [
    "# Training/validation/test data split\n",
    "np.random.seed(10)\n",
    "idxs = np.random.permutation(len(y_filt))\n",
    "split_va, split_te = int(0.64 * len(y_filt)), int(0.8 * len(y_filt)) #64% training, 16% validation, 20% test\n",
    "idx_tr, idx_va, idx_te = np.split(idxs, [split_va, split_te])\n",
    "X_tr, X_va, X_te = X_filt[idx_tr], X_filt[idx_va], X_filt[idx_te]\n",
    "y_tr, y_va, y_te = y_filt[idx_tr], y_filt[idx_va], y_filt[idx_te]\n",
    "\n",
    "print(f'Training data: {np.round(len(y_tr)/len(y_filt),2)*100}%')\n",
    "print(f'Validation data: {np.round(len(y_va)/len(y_filt),2)*100}%')\n",
    "print(f'Test data: {np.round(len(y_te)/len(y_filt),2)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "regr = linear_model.LogisticRegression(penalty='l1',\n",
    "    solver='saga',  # or 'liblinear'\n",
    "    C=10000)\n",
    "regr = linear_model.LogisticRegression()\n",
    "regr.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 51.72%\n",
      "Validation Accuracy: 51.75%\n"
     ]
    }
   ],
   "source": [
    "y_pred_tr = regr.predict(X_tr)\n",
    "y_pred_va = regr.predict(X_va)\n",
    "print(f'Train Accuracy: {np.round(metrics.accuracy_score(y_tr, y_pred_tr)*100,2)}%')\n",
    "print(f'Validation Accuracy: {np.round(metrics.accuracy_score(y_va, y_pred_va)*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MMR Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load X and y data\n",
    "with open('../data/standard_v1/X.npy', 'rb') as f:\n",
    "    X = np.load(f)\n",
    "with open('../data/standard_v1/y.npy', 'rb') as f:\n",
    "    y = np.load(f)\n",
    "\n",
    "# Removed attack backswing feature\n",
    "X = np.delete(X,14,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nick_\\.virtualenvs\\dotaprediction-1-raZixZ\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMR group 1\n",
      "Train Accuracy: 52.57%\n",
      "Validation Accuracy: 52.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nick_\\.virtualenvs\\dotaprediction-1-raZixZ\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMR group 2\n",
      "Train Accuracy: 52.42%\n",
      "Validation Accuracy: 52.5%\n",
      "MMR group 3\n",
      "Train Accuracy: 52.4%\n",
      "Validation Accuracy: 52.3%\n",
      "MMR group 4\n",
      "Train Accuracy: 52.26%\n",
      "Validation Accuracy: 52.19%\n",
      "MMR group 5\n",
      "Train Accuracy: 51.9%\n",
      "Validation Accuracy: 51.9%\n",
      "MMR group 6\n",
      "Train Accuracy: 51.33%\n",
      "Validation Accuracy: 51.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nick_\\.virtualenvs\\dotaprediction-1-raZixZ\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "for group in range(1,7):\n",
    "    # Filter data: standard filter + MMR\n",
    "    filt = get_filt_idx(df_filters['filt_std'].values & df_filters[f'filt_mmr_{group}'].values)\n",
    "    X_filt = X[filt]\n",
    "    y_filt = y[filt]\n",
    "    # Training/validation/test data split\n",
    "    np.random.seed(10)\n",
    "    idxs = np.random.permutation(len(y_filt))\n",
    "    split_va, split_te = int(0.7 * len(y_filt)), int(1.0 * len(y_filt)) #70% training, 30% validation\n",
    "    idx_tr, idx_va, idx_te = np.split(idxs, [split_va, split_te])\n",
    "    X_tr, X_va, X_te = X_filt[idx_tr], X_filt[idx_va], X_filt[idx_te]\n",
    "    y_tr, y_va, y_te = y_filt[idx_tr], y_filt[idx_va], y_filt[idx_te]\n",
    "\n",
    "    # Fit model\n",
    "    regr = linear_model.LogisticRegression(penalty='l1',\n",
    "        solver='saga',  # or 'liblinear'\n",
    "        C=10000)\n",
    "    regr = linear_model.LogisticRegression()\n",
    "    regr.fit(X_tr, y_tr)\n",
    "\n",
    "    y_pred_tr = regr.predict(X_tr)\n",
    "    y_pred_va = regr.predict(X_va)\n",
    "    print(f'MMR group {group}')\n",
    "    print(f'Train Accuracy: {np.round(metrics.accuracy_score(y_tr, y_pred_tr)*100,2)}%')\n",
    "    print(f'Validation Accuracy: {np.round(metrics.accuracy_score(y_va, y_pred_va)*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duration Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load X and y data\n",
    "with open('../data/standard_v1/X.npy', 'rb') as f:\n",
    "    X = np.load(f)\n",
    "with open('../data/standard_v1/y.npy', 'rb') as f:\n",
    "    y = np.load(f)\n",
    "\n",
    "# Removed attack backswing feature\n",
    "X = np.delete(X,14,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nick_\\.virtualenvs\\dotaprediction-1-raZixZ\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration group 1 ... tr: 916706 /// va: 392874\n",
      "Train Accuracy: 56.45%\n",
      "Validation Accuracy: 56.45%\n",
      "Duration group 2 ... tr: 1756997 /// va: 752999\n",
      "Train Accuracy: 53.39%\n",
      "Validation Accuracy: 53.37%\n",
      "Duration group 3 ... tr: 1723446 /// va: 738620\n",
      "Train Accuracy: 52.37%\n",
      "Validation Accuracy: 52.26%\n",
      "Duration group 4 ... tr: 1450533 /// va: 621657\n",
      "Train Accuracy: 52.59%\n",
      "Validation Accuracy: 52.5%\n",
      "Duration group 5 ... tr: 802573 /// va: 343961\n",
      "Train Accuracy: 52.67%\n",
      "Validation Accuracy: 52.6%\n",
      "Duration group 6 ... tr: 458005 /// va: 196289\n",
      "Train Accuracy: 52.65%\n",
      "Validation Accuracy: 52.54%\n"
     ]
    }
   ],
   "source": [
    "for group in range(1,7):\n",
    "    # Filter data: standard filter + duration\n",
    "    filt = get_filt_idx(df_filters['filt_std'].values & df_filters[f'filt_duration_{group}'].values)\n",
    "    X_filt = X[filt]\n",
    "    y_filt = y[filt]\n",
    "    # Training/validation/test data split\n",
    "    np.random.seed(10)\n",
    "    idxs = np.random.permutation(len(y_filt))\n",
    "    split_va, split_te = int(0.7 * len(y_filt)), int(1.0 * len(y_filt)) #70% training, 30% validation\n",
    "    idx_tr, idx_va, idx_te = np.split(idxs, [split_va, split_te])\n",
    "    X_tr, X_va, X_te = X_filt[idx_tr], X_filt[idx_va], X_filt[idx_te]\n",
    "    y_tr, y_va, y_te = y_filt[idx_tr], y_filt[idx_va], y_filt[idx_te]\n",
    "\n",
    "    # Fit model\n",
    "    regr = linear_model.LogisticRegression(penalty='l1',\n",
    "        solver='saga',  # or 'liblinear'\n",
    "        C=10000)\n",
    "    regr = linear_model.LogisticRegression()\n",
    "    regr.fit(X_tr, y_tr)\n",
    "\n",
    "    y_pred_tr = regr.predict(X_tr)\n",
    "    y_pred_va = regr.predict(X_va)\n",
    "    print(f'Duration group {group} ... tr: {len(y_tr)} /// va: {len(y_va)}')\n",
    "    print(f'Train Accuracy: {np.round(metrics.accuracy_score(y_tr, y_pred_tr)*100,2)}%')\n",
    "    print(f'Validation Accuracy: {np.round(metrics.accuracy_score(y_va, y_pred_va)*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dotaprediction-1-raZixZ')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5583eed7e2a3e408b4f876e745cfacd4c116e2014afad04a178d763bb8d713ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
