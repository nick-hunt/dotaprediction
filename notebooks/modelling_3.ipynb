{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import dataset\n",
    "from importlib import reload\n",
    "reload(dataset)\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load combined data\n",
    "df = pd.read_csv('../data/combined.csv')\n",
    "\n",
    "# Load hero feature data\n",
    "df_features = pd.read_csv('../data/features.csv')\n",
    "df_features = df_features.set_index('hero_id')\n",
    "\n",
    "# Load standard filter\n",
    "df_filters = pd.read_csv('../models/filters.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/graphs_v1_scaled/graphs_v1_scaled_0-49999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_50000-99999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_100000-149999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_150000-199999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_200000-249999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_250000-299999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_300000-349999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_350000-399999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_400000-449999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_450000-499999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_500000-549999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_550000-599999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_600000-649999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_650000-699999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_700000-749999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_750000-799999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_800000-849999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_850000-899999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_900000-949999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_950000-999999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1000000-1049999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1050000-1099999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1100000-1149999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1150000-1199999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1200000-1249999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1250000-1299999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1300000-1349999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1350000-1399999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1400000-1449999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1450000-1499999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1500000-1549999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1550000-1599999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1600000-1649999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1650000-1699999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1700000-1749999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1750000-1799999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1800000-1849999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1850000-1899999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1900000-1949999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1950000-1999999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2000000-2049999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2050000-2099999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2100000-2149999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2150000-2199999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2200000-2249999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2250000-2299999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2300000-2349999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2350000-2399999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2400000-2449999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2450000-2499999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2500000-2549999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2550000-2599999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2600000-2649999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2650000-2699999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2700000-2749999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2750000-2799999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2800000-2849999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2850000-2899999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2900000-2949999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2950000-2999999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3000000-3049999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3050000-3099999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3100000-3149999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3150000-3199999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3200000-3249999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3250000-3299999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3300000-3349999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3350000-3399999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3400000-3449999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3450000-3499999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3500000-3549999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3550000-3599999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3600000-3649999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3650000-3699999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3700000-3749999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3750000-3799999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3800000-3849999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3850000-3899999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3900000-3949999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3950000-3999999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4000000-4049999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4050000-4099999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4100000-4149999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4150000-4199999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4200000-4249999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4250000-4299999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4300000-4349999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4350000-4399999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4400000-4449999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4450000-4499999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4500000-4549999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4550000-4599999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4600000-4649999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4650000-4699999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4700000-4749999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4750000-4799999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4800000-4849999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4850000-4899999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4900000-4949999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4950000-4999999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5000000-5049999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5050000-5099999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5100000-5149999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5150000-5199999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5200000-5249999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5250000-5299999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5300000-5349999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5350000-5399999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5400000-5449999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5450000-5499999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5500000-5549999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5550000-5599999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5600000-5600751.pkl\n"
     ]
    }
   ],
   "source": [
    "# Graph data already has the scaled features and match results\n",
    "# Load graph dataset 50000 matches at a time\n",
    "dir = '../data/graphs_v1_scaled/'\n",
    "count = 0\n",
    "total = len(df)\n",
    "step = 50000\n",
    "\n",
    "for i in range(0,int(np.ceil(total/step))):\n",
    "    start = i*step\n",
    "    end = start+step-1 if (start+step)<total else total-1\n",
    "    path = dir+f'graphs_v1_scaled_{start}-{end}.pkl'\n",
    "    print(path)\n",
    "    file = open(path,'rb')\n",
    "    if i==0:\n",
    "        graphs = pickle.load(file)\n",
    "    else:\n",
    "        graphs = graphs + pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filt_idx(filt):\n",
    "    '''Returns indices of desired matches given a boolean array filter e.g. True, False, True returns [0,2]'''\n",
    "    # DotaV1 data handling (two graphs for every match: 0-49999 radiant, 0-49999 dire, 50000-99999 radiant, etc.)\n",
    "    step = 50000\n",
    "    filt_vals = []\n",
    "    for i in range(0,int(np.ceil(len(filt)/step))):\n",
    "        start = i*step\n",
    "        end = start+step\n",
    "        # Add filters for match range twice, as matches repeated every 50000\n",
    "        filt_vals = np.append(filt_vals, filt[start:end])\n",
    "        filt_vals = np.append(filt_vals, filt[start:end])\n",
    "\n",
    "    # Get indices of True values in filters\n",
    "    filt_idx = [i for i, x in enumerate(filt_vals) if x]\n",
    "    return filt_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard filtering complete\n"
     ]
    }
   ],
   "source": [
    "# Filter graph dataset\n",
    "filt = df_filters['filt_std'].values\n",
    "filt_idx = get_filt_idx(filt)\n",
    "graphs_filt = graphs[filt_idx]\n",
    "print('Standard filtering complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack backswing feature removed\n"
     ]
    }
   ],
   "source": [
    "# Remove attack_backswing feature\n",
    "for i in range(0,len(graphs_filt)):\n",
    "    # if(i%100000==0):\n",
    "    graphs_filt[i].x = graphs_filt[i].x[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,15,16,17,18,19]] # remove attack_backswing as a feature\n",
    "print('Attack backswing feature removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 64.0%\n",
      "Validation data: 16.0%\n",
      "Test data: 20.0%\n"
     ]
    }
   ],
   "source": [
    "# Split graphs into training/validation/test\n",
    "np.random.seed(10)\n",
    "idxs = np.random.permutation(len(graphs_filt))\n",
    "split_va, split_te = int(0.64 * len(graphs_filt)), int(0.8 * len(graphs_filt)) #64% training, 16% validation, 20% test\n",
    "idx_tr, idx_va, idx_te = np.split(idxs, [split_va, split_te])\n",
    "data_tr = graphs_filt[idx_tr]\n",
    "data_va = graphs_filt[idx_va]\n",
    "data_te = graphs_filt[idx_te]\n",
    "\n",
    "print(f'Training data: {np.round(len(data_tr)/len(graphs_filt),2)*100}%')\n",
    "print(f'Validation data: {np.round(len(data_va)/len(graphs_filt),2)*100}%')\n",
    "print(f'Test data: {np.round(len(data_te)/len(graphs_filt),2)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3100000\n",
      "3200000\n",
      "3300000\n",
      "3400000\n",
      "3500000\n",
      "3600000\n",
      "3700000\n",
      "3800000\n",
      "3900000\n",
      "4000000\n",
      "4100000\n",
      "4200000\n",
      "4300000\n",
      "4400000\n",
      "4500000\n",
      "4600000\n",
      "4700000\n",
      "4800000\n",
      "4900000\n",
      "5000000\n",
      "5100000\n",
      "5200000\n",
      "5300000\n",
      "5400000\n",
      "5500000\n",
      "5600000\n",
      "5700000\n",
      "5800000\n",
      "5900000\n",
      "6000000\n",
      "6100000\n",
      "6200000\n",
      "6300000\n",
      "6400000\n",
      "6500000\n"
     ]
    }
   ],
   "source": [
    "# Create training/validation/test data from graph splits\n",
    "# Training\n",
    "X_tr = np.empty([len(data_tr), 19])\n",
    "y_tr = np.empty(len(data_tr))\n",
    "\n",
    "for i, graph in enumerate(data_tr):\n",
    "    if i%100000==0:\n",
    "        print(i)\n",
    "    X_tr[i,:] = np.mean(data_tr[i].x,0)\n",
    "    y_tr[i] = data_tr[i].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_tr.npy', 'wb') as f:\n",
    "    np.save(f, X_tr)\n",
    "with open('y_tr.npy', 'wb') as f:\n",
    "    np.save(f, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "X_va = np.empty([len(data_va), 19])\n",
    "y_va = np.empty(len(data_va))\n",
    "\n",
    "for i, graph in enumerate(data_va):\n",
    "    if i%100000==0:\n",
    "        print(i)\n",
    "    X_va[i,:] = np.mean(data_va[i].x,0)\n",
    "    y_va[i] = data_va[i].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_va.npy', 'wb') as f:\n",
    "    np.save(f, X_va)\n",
    "with open('y_va.npy', 'wb') as f:\n",
    "    np.save(f, y_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "X_te = np.empty([len(data_te), 19])\n",
    "y_te = np.empty(len(data_te))\n",
    "\n",
    "for i, graph in enumerate(data_te):\n",
    "    if i%100000==0:\n",
    "        print(i)\n",
    "    X_te[i,:] = np.mean(data_te[i].x,0)\n",
    "    y_te[i] = data_te[i].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_te.npy', 'wb') as f:\n",
    "    np.save(f, X_te)\n",
    "with open('y_te.npy', 'wb') as f:\n",
    "    np.save(f, y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5078155.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = linear_model.LogisticRegression(penalty='l1',\n",
    "    solver='saga',  # or 'liblinear'\n",
    "    C=10000)\n",
    "regr = linear_model.LogisticRegression()\n",
    "regr.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = regr.predict(X_test_s)\n",
    "y_pred_train = regr.predict(X_train_s)\n",
    "print(f'Train Accuracy: {metrics.accuracy_score(y_train, y_pred_train)}')\n",
    "print(f'Test Accuracy: {metrics.accuracy_score(y_test, y_pred_test)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dotaprediction-1-raZixZ')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5583eed7e2a3e408b4f876e745cfacd4c116e2014afad04a178d763bb8d713ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
