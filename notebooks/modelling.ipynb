{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library and data imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spektral.data import Dataset, Graph\n",
    "import dataset\n",
    "reload(dataset)\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from spektral.data import BatchLoader\n",
    "from spektral.layers import GATConv, GCNConv, GlobalAvgPool, GlobalMaxPool, GlobalSumPool, GlobalAttentionPool\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.config import list_physical_devices\n",
    "from tensorflow.python.client import device_lib\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load combined data\n",
    "df_raw = pd.read_csv('../data/combined.csv')\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Load hero feature data\n",
    "df_features = pd.read_csv('../data/features.csv')\n",
    "df_features = df_features.set_index('hero_id')\n",
    "\n",
    "# Load standard filter\n",
    "df_filters = pd.read_csv('../models/filters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/graphs_v1_scaled/graphs_v1_scaled_0-49999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_50000-99999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_100000-149999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_150000-199999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_200000-249999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_250000-299999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_300000-349999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_350000-399999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_400000-449999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_450000-499999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_500000-549999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_550000-599999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_600000-649999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_650000-699999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_700000-749999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_750000-799999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_800000-849999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_850000-899999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_900000-949999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_950000-999999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1000000-1049999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1050000-1099999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1100000-1149999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1150000-1199999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1200000-1249999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1250000-1299999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1300000-1349999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1350000-1399999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1400000-1449999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1450000-1499999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1500000-1549999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1550000-1599999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1600000-1649999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1650000-1699999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1700000-1749999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1750000-1799999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1800000-1849999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1850000-1899999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1900000-1949999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_1950000-1999999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2000000-2049999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2050000-2099999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2100000-2149999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2150000-2199999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2200000-2249999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2250000-2299999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2300000-2349999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2350000-2399999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2400000-2449999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2450000-2499999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2500000-2549999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2550000-2599999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2600000-2649999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2650000-2699999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2700000-2749999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2750000-2799999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2800000-2849999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2850000-2899999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2900000-2949999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_2950000-2999999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3000000-3049999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3050000-3099999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3100000-3149999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3150000-3199999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3200000-3249999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3250000-3299999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3300000-3349999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3350000-3399999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3400000-3449999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3450000-3499999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3500000-3549999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3550000-3599999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3600000-3649999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3650000-3699999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3700000-3749999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3750000-3799999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3800000-3849999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3850000-3899999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3900000-3949999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_3950000-3999999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4000000-4049999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4050000-4099999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4100000-4149999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4150000-4199999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4200000-4249999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4250000-4299999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4300000-4349999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4350000-4399999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4400000-4449999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4450000-4499999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4500000-4549999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4550000-4599999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4600000-4649999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4650000-4699999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4700000-4749999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4750000-4799999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4800000-4849999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4850000-4899999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4900000-4949999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_4950000-4999999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5000000-5049999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5050000-5099999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5100000-5149999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5150000-5199999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5200000-5249999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5250000-5299999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5300000-5349999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5350000-5399999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5400000-5449999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5450000-5499999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5500000-5549999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5550000-5599999.pkl\n",
      "../data/graphs_v1_scaled/graphs_v1_scaled_5600000-5600751.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load graph dataset 50000 matches at a time\n",
    "dir = '../data/graphs_v1_scaled/'\n",
    "count = 0\n",
    "total = len(df)\n",
    "step = 50000\n",
    "\n",
    "for i in range(0,int(np.ceil(total/step))):\n",
    "    start = i*step\n",
    "    end = start+step-1 if (start+step)<total else total-1\n",
    "    path = dir+f'graphs_v1_scaled_{start}-{end}.pkl'\n",
    "    print(path)\n",
    "    file = open(path,'rb')\n",
    "    if i==0:\n",
    "        graphs = pickle.load(file)\n",
    "    else:\n",
    "        graphs = graphs + pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filt_idx(filt):\n",
    "    '''Returns indices of desired matches given a boolean array filter e.g. True, False, True returns [0,2]'''\n",
    "    # DotaV1 data handling (two graphs for every match: 0-49999 radiant, 0-49999 dire, 50000-99999 radiant, etc.)\n",
    "    step = 50000\n",
    "    filt_vals = []\n",
    "    for i in range(0,int(np.ceil(len(filt)/step))):\n",
    "        start = i*step\n",
    "        end = start+step\n",
    "        # Add filters for match range twice, as matches repeated every 50000\n",
    "        filt_vals = np.append(filt_vals, filt[start:end])\n",
    "        filt_vals = np.append(filt_vals, filt[start:end])\n",
    "\n",
    "    # Get indices of True values in filters\n",
    "    filt_idx = [i for i, x in enumerate(filt_vals) if x]\n",
    "    return filt_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling - data now pre-scaled\n",
    "# # MinMax Scaler model to normalise features from 0-1\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(df_features.iloc[:,3:].to_numpy())\n",
    "\n",
    "# # Loop through each graph and scale feature matrix and drop attack_backswing feature\n",
    "# print('Scaling graph dataset feature matrices:')\n",
    "# for i in range(0,len(graphs_filt)):\n",
    "#     if(i%100000==0):\n",
    "#         print(i)\n",
    "#     graphs_filt[i].x = scaler.transform(graphs_filt[i].x) # scale feature matrix\n",
    "#     graphs_filt[i].x = np.delete(graphs_filt[i].x, 14, 1) # remove attack_backswing as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard filtering complete\n"
     ]
    }
   ],
   "source": [
    "# Filter graph dataset\n",
    "filt = df_filters['filt_std'].values\n",
    "filt_idx = get_filt_idx(filt)\n",
    "graphs_filt = graphs[filt_idx]\n",
    "print('Standard filtering complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack backswing feature removed\n"
     ]
    }
   ],
   "source": [
    "# Remove attack_backswing feature\n",
    "for i in range(0,len(graphs_filt)):\n",
    "    # if(i%100000==0):\n",
    "    graphs_filt[i].x = graphs_filt[i].x[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,15,16,17,18,19]] # remove attack_backswing as a feature\n",
    "print('Attack backswing feature removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 64.0%\n",
      "Validation data: 16.0%\n",
      "Test data: 20.0%\n"
     ]
    }
   ],
   "source": [
    "# Train/valid/test split\n",
    "d = graphs_filt # Graph data\n",
    "\n",
    "np.random.seed(10)\n",
    "idxs = np.random.permutation(len(d))\n",
    "split_va, split_te = int(0.64 * len(d)), int(0.8 * len(d)) #64% training, 16% validation, 20% test\n",
    "idx_tr, idx_va, idx_te = np.split(idxs, [split_va, split_te])\n",
    "data_tr = d[idx_tr]\n",
    "data_va = d[idx_va]\n",
    "data_te = d[idx_te]\n",
    "\n",
    "print(f'Training data: {np.round(len(data_tr)/len(graphs_filt),2)*100}%')\n",
    "print(f'Validation data: {np.round(len(data_va)/len(graphs_filt),2)*100}%')\n",
    "print(f'Test data: {np.round(len(data_te)/len(graphs_filt),2)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm GPUs are being identified (requires tf environment, not the pipenv dotaprediction)\n",
    "# print(\"Num GPUs Available: \", list_physical_devices('GPU'))\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1.0 - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nick_\\.virtualenvs\\dotaprediction-eZ2WDOkz\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning:\n",
      "\n",
      "you are shuffling a 'DotaV1' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25391/25391 [==============================] - 225s 9ms/step - loss: 0.6922 - binary_accuracy: 0.5185 - val_loss: 0.6915 - val_binary_accuracy: 0.5228\n",
      "Epoch 2/50\n",
      "25391/25391 [==============================] - 133s 5ms/step - loss: 0.6914 - binary_accuracy: 0.5241 - val_loss: 0.6914 - val_binary_accuracy: 0.5238\n",
      "Epoch 3/50\n",
      "25391/25391 [==============================] - 135s 5ms/step - loss: 0.6912 - binary_accuracy: 0.5252 - val_loss: 0.6918 - val_binary_accuracy: 0.5228\n",
      "Epoch 4/50\n",
      "25391/25391 [==============================] - 136s 5ms/step - loss: 0.6912 - binary_accuracy: 0.5256 - val_loss: 0.6918 - val_binary_accuracy: 0.5222\n",
      "Epoch 5/50\n",
      "25391/25391 [==============================] - 149s 6ms/step - loss: 0.6911 - binary_accuracy: 0.5260 - val_loss: 0.6910 - val_binary_accuracy: 0.5266\n",
      "Epoch 6/50\n",
      "25391/25391 [==============================] - 131s 5ms/step - loss: 0.6911 - binary_accuracy: 0.5264 - val_loss: 0.6912 - val_binary_accuracy: 0.5252\n",
      "Epoch 7/50\n",
      "25391/25391 [==============================] - 129s 5ms/step - loss: 0.6910 - binary_accuracy: 0.5264 - val_loss: 0.6909 - val_binary_accuracy: 0.5268\n",
      "Epoch 8/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6910 - binary_accuracy: 0.5266 - val_loss: 0.6909 - val_binary_accuracy: 0.5270\n",
      "Epoch 9/50\n",
      "25391/25391 [==============================] - 129s 5ms/step - loss: 0.6910 - binary_accuracy: 0.5266 - val_loss: 0.6908 - val_binary_accuracy: 0.5278\n",
      "Epoch 10/50\n",
      "25391/25391 [==============================] - 129s 5ms/step - loss: 0.6909 - binary_accuracy: 0.5271 - val_loss: 0.6910 - val_binary_accuracy: 0.5270\n",
      "Epoch 11/50\n",
      "25391/25391 [==============================] - 127s 5ms/step - loss: 0.6909 - binary_accuracy: 0.5268 - val_loss: 0.6908 - val_binary_accuracy: 0.5277\n",
      "Epoch 12/50\n",
      "25391/25391 [==============================] - 131s 5ms/step - loss: 0.6909 - binary_accuracy: 0.5269 - val_loss: 0.6910 - val_binary_accuracy: 0.5270\n",
      "Epoch 13/50\n",
      "25391/25391 [==============================] - 138s 5ms/step - loss: 0.6909 - binary_accuracy: 0.5270 - val_loss: 0.6918 - val_binary_accuracy: 0.5231\n",
      "Epoch 14/50\n",
      "25391/25391 [==============================] - 137s 5ms/step - loss: 0.6909 - binary_accuracy: 0.5273 - val_loss: 0.6907 - val_binary_accuracy: 0.5282\n",
      "Epoch 15/50\n",
      "25391/25391 [==============================] - 143s 6ms/step - loss: 0.6909 - binary_accuracy: 0.5272 - val_loss: 0.6908 - val_binary_accuracy: 0.5273\n",
      "Epoch 16/50\n",
      "25391/25391 [==============================] - 142s 6ms/step - loss: 0.6909 - binary_accuracy: 0.5273 - val_loss: 0.6908 - val_binary_accuracy: 0.5273\n",
      "Epoch 17/50\n",
      "25391/25391 [==============================] - 131s 5ms/step - loss: 0.6909 - binary_accuracy: 0.5273 - val_loss: 0.6912 - val_binary_accuracy: 0.5275\n",
      "Epoch 18/50\n",
      "25391/25391 [==============================] - 135s 5ms/step - loss: 0.6909 - binary_accuracy: 0.5274 - val_loss: 0.6909 - val_binary_accuracy: 0.5273\n",
      "Epoch 19/50\n",
      "25391/25391 [==============================] - 143s 6ms/step - loss: 0.6909 - binary_accuracy: 0.5273 - val_loss: 0.6907 - val_binary_accuracy: 0.5272\n",
      "Epoch 20/50\n",
      "25391/25391 [==============================] - 141s 6ms/step - loss: 0.6909 - binary_accuracy: 0.5273 - val_loss: 0.6909 - val_binary_accuracy: 0.5269\n",
      "Epoch 21/50\n",
      "25391/25391 [==============================] - 141s 6ms/step - loss: 0.6909 - binary_accuracy: 0.5272 - val_loss: 0.6914 - val_binary_accuracy: 0.5257\n",
      "Epoch 22/50\n",
      "25391/25391 [==============================] - 140s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5274 - val_loss: 0.6907 - val_binary_accuracy: 0.5283\n",
      "Epoch 23/50\n",
      "25391/25391 [==============================] - 138s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5273 - val_loss: 0.6909 - val_binary_accuracy: 0.5268\n",
      "Epoch 24/50\n",
      "25391/25391 [==============================] - 138s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5275 - val_loss: 0.6909 - val_binary_accuracy: 0.5265\n",
      "Epoch 25/50\n",
      "25391/25391 [==============================] - 138s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5274 - val_loss: 0.6909 - val_binary_accuracy: 0.5272\n",
      "Epoch 26/50\n",
      "25391/25391 [==============================] - 133s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5275 - val_loss: 0.6908 - val_binary_accuracy: 0.5275\n",
      "Epoch 27/50\n",
      "25391/25391 [==============================] - 125s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5274 - val_loss: 0.6907 - val_binary_accuracy: 0.5282\n",
      "Epoch 28/50\n",
      "25391/25391 [==============================] - 128s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5275 - val_loss: 0.6908 - val_binary_accuracy: 0.5275\n",
      "Epoch 29/50\n",
      "25391/25391 [==============================] - 128s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5273 - val_loss: 0.6910 - val_binary_accuracy: 0.5261\n",
      "Epoch 30/50\n",
      "25391/25391 [==============================] - 128s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5277 - val_loss: 0.6914 - val_binary_accuracy: 0.5236\n",
      "Epoch 31/50\n",
      "25391/25391 [==============================] - 128s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5274 - val_loss: 0.6911 - val_binary_accuracy: 0.5257\n",
      "Epoch 32/50\n",
      "25391/25391 [==============================] - 129s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5275 - val_loss: 0.6910 - val_binary_accuracy: 0.5254\n",
      "Epoch 33/50\n",
      "25391/25391 [==============================] - 129s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5275 - val_loss: 0.6910 - val_binary_accuracy: 0.5265\n",
      "Epoch 34/50\n",
      "25391/25391 [==============================] - 129s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5277 - val_loss: 0.6909 - val_binary_accuracy: 0.5278\n",
      "Epoch 35/50\n",
      "25391/25391 [==============================] - 129s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5276 - val_loss: 0.6907 - val_binary_accuracy: 0.5278\n",
      "Epoch 36/50\n",
      "25391/25391 [==============================] - 129s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5276 - val_loss: 0.6907 - val_binary_accuracy: 0.5281\n",
      "Epoch 37/50\n",
      "25391/25391 [==============================] - 129s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5277 - val_loss: 0.6906 - val_binary_accuracy: 0.5281\n",
      "Epoch 38/50\n",
      "25391/25391 [==============================] - 129s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5276 - val_loss: 0.6914 - val_binary_accuracy: 0.5254\n",
      "Epoch 39/50\n",
      "25391/25391 [==============================] - 130s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5277 - val_loss: 0.6910 - val_binary_accuracy: 0.5263\n",
      "Epoch 40/50\n",
      "25391/25391 [==============================] - 130s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5277 - val_loss: 0.6911 - val_binary_accuracy: 0.5258\n",
      "Epoch 41/50\n",
      "25391/25391 [==============================] - 130s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5277 - val_loss: 0.6908 - val_binary_accuracy: 0.5281\n",
      "Epoch 42/50\n",
      "25391/25391 [==============================] - 130s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5276 - val_loss: 0.6911 - val_binary_accuracy: 0.5255\n",
      "Epoch 43/50\n",
      "25391/25391 [==============================] - 130s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5276 - val_loss: 0.6907 - val_binary_accuracy: 0.5279\n",
      "Epoch 44/50\n",
      "25391/25391 [==============================] - 131s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5277 - val_loss: 0.6907 - val_binary_accuracy: 0.5281\n",
      "Epoch 45/50\n",
      "25391/25391 [==============================] - 130s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5279 - val_loss: 0.6909 - val_binary_accuracy: 0.5268\n",
      "Epoch 46/50\n",
      "25391/25391 [==============================] - 131s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5276 - val_loss: 0.6907 - val_binary_accuracy: 0.5276\n",
      "Epoch 47/50\n",
      "25391/25391 [==============================] - 131s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5277 - val_loss: 0.6909 - val_binary_accuracy: 0.5273\n",
      "Epoch 48/50\n",
      "25391/25391 [==============================] - 131s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5276 - val_loss: 0.6908 - val_binary_accuracy: 0.5277\n",
      "Epoch 49/50\n",
      "25391/25391 [==============================] - 131s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5277 - val_loss: 0.6907 - val_binary_accuracy: 0.5278\n",
      "Epoch 50/50\n",
      "25391/25391 [==============================] - 109s 4ms/step - loss: 0.6908 - binary_accuracy: 0.5277 - val_loss: 0.6908 - val_binary_accuracy: 0.5271\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "learning_rate = 0.001  # Learning rate\n",
    "epochs = 50  # Number of training epochs\n",
    "es_patience = 10  # Patience for early stopping\n",
    "batch_size = 256  # Batch size\n",
    "\n",
    "# Data loaders\n",
    "loader_tr = BatchLoader(data_tr, batch_size=batch_size, epochs=epochs)\n",
    "loader_va = BatchLoader(data_va, batch_size=batch_size)\n",
    "loader_te = BatchLoader(data_te, batch_size=batch_size)\n",
    "\n",
    "# Build model\n",
    "class Net_1_0(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(19, activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.dense = Dense(d.n_labels, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        # x.shape is [n_batches, 5, n_ features]\n",
    "        # a.shape is [n_batches, 5, 5]\n",
    "\n",
    "        x = self.conv1([x, a])\n",
    "        # x.shape is [n_batches, 5, channels] where I have set channels = features (20)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        # x.shape is [n_batches, 5*channels]\n",
    "\n",
    "        x = self.dense(x)\n",
    "        # output.shape is [n_batches, 1]\n",
    "        \n",
    "        return x\n",
    "\n",
    "model_1_0 = Net_1_0()\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "loss_fn = BinaryCrossentropy()\n",
    "model_1_0.compile(optimizer=optimizer, loss=loss_fn, metrics=['binary_accuracy'])\n",
    "\n",
    "fit_log_1_0 = model_1_0.fit(loader_tr.load(), steps_per_epoch=loader_tr.steps_per_epoch, epochs=epochs, validation_data=loader_va.load(), validation_steps=loader_va.steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "Training",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          0.518520176410675,
          0.524085521697998,
          0.5252493619918823,
          0.5255624651908875,
          0.5260255336761475,
          0.5263992547988892,
          0.5264129042625427,
          0.5265921354293823,
          0.5266475081443787,
          0.5270941257476807,
          0.5268241763114929,
          0.5268999934196472,
          0.5269619822502136,
          0.5273481607437134,
          0.5272284746170044,
          0.5272550582885742,
          0.5272901654243469,
          0.5273721218109131,
          0.5272883176803589,
          0.5273247361183167,
          0.5272200107574463,
          0.5273506045341492,
          0.5273398160934448,
          0.5275078415870667,
          0.5273507833480835,
          0.5275152325630188,
          0.5273701548576355,
          0.5274658203125,
          0.5273460149765015,
          0.5276632308959961,
          0.527437686920166,
          0.5274830460548401,
          0.527529239654541,
          0.5277416706085205,
          0.5276238322257996,
          0.5275581479072571,
          0.527656614780426,
          0.5275681614875793,
          0.5276721715927124,
          0.527668297290802,
          0.5276849269866943,
          0.5276442766189575,
          0.5275850892066956,
          0.5276641249656677,
          0.5278575420379639,
          0.5276166200637817,
          0.5277166366577148,
          0.5276426076889038,
          0.5276696681976318,
          0.5277312397956848
         ]
        },
        {
         "mode": "lines",
         "name": "Validation",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          0.522817075252533,
          0.5237820148468018,
          0.5227629542350769,
          0.5221691131591797,
          0.5265524387359619,
          0.5251930952072144,
          0.5267881155014038,
          0.52701336145401,
          0.5277549028396606,
          0.5269672274589539,
          0.5277032256126404,
          0.5269721150398254,
          0.523061990737915,
          0.5281567573547363,
          0.5273081660270691,
          0.5272619724273682,
          0.5274650454521179,
          0.5273191928863525,
          0.5272447466850281,
          0.5269056558609009,
          0.5256650447845459,
          0.5282884240150452,
          0.5268084406852722,
          0.5265013575553894,
          0.5272053480148315,
          0.5274718403816223,
          0.5281770825386047,
          0.5275487303733826,
          0.5261358618736267,
          0.5236263275146484,
          0.5257235169410706,
          0.525378942489624,
          0.5265333652496338,
          0.5278324484825134,
          0.5278337001800537,
          0.528089702129364,
          0.5280982851982117,
          0.5253899693489075,
          0.5262693762779236,
          0.525847852230072,
          0.5280730724334717,
          0.5255174040794373,
          0.5279462933540344,
          0.5280545949935913,
          0.5267850756645203,
          0.5276318192481995,
          0.5272656679153442,
          0.5277487635612488,
          0.5277678370475769,
          0.5271247625350952
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "scatter": [
           {
            "type": "scatter"
           }
          ]
         }
        },
        "xaxis": {
         "dtick": 1,
         "tick0": 0,
         "title": {
          "text": "Epochs"
         }
        },
        "yaxis": {
         "title": {
          "text": "Accuracy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "epochs = list(range(1,len(fit_log_1_0.history['binary_accuracy'])+1))\n",
    "training_accuracy = fit_log_1_0.history['binary_accuracy']\n",
    "validation_accuracy = fit_log_1_0.history['val_binary_accuracy']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=training_accuracy,\n",
    "    mode='lines',\n",
    "    name='Training'))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=validation_accuracy,\n",
    "    mode='lines',\n",
    "    name='Validation'))\n",
    "fig.update_layout(\n",
    "    template='none',\n",
    "    xaxis_title='Epochs',\n",
    "    yaxis_title=\"Accuracy\")\n",
    "fig.update_xaxes(tick0=0, dtick=1)\n",
    "# fig.update_yaxes(range=[0.5,1])\n",
    "fig.show()\n",
    "fig.write_image(f'../images/model_1_0_accuracy.png', scale=5)\n",
    "pd.DataFrame({'epoch': epochs, 'training_accuracy':training_accuracy, 'validation_accuracy':validation_accuracy}).to_csv('../images/model_1_0_accuracy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://639f241c-8626-491f-b1e7-68ee9353ea29/assets\n",
      "INFO:tensorflow:Assets written to: ram://d5d9e920-b04a-42b1-9c2f-a6666cc80e66/assets\n"
     ]
    }
   ],
   "source": [
    "filehandler = open(f'../models/fit_log_1_0.pkl','wb')\n",
    "pickle.dump(fit_log_1_0, filehandler)\n",
    "filehandler = open(f'../models/model_1_0.pkl','wb')\n",
    "pickle.dump(model_1_0, filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1.1 - GATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25391/25391 [==============================] - 220s 9ms/step - loss: 0.6913 - binary_accuracy: 0.5259 - val_loss: 0.6904 - val_binary_accuracy: 0.5317\n",
      "Epoch 2/50\n",
      "25391/25391 [==============================] - 213s 8ms/step - loss: 0.6908 - binary_accuracy: 0.5300 - val_loss: 0.6902 - val_binary_accuracy: 0.5332\n",
      "Epoch 3/50\n",
      "25391/25391 [==============================] - 209s 8ms/step - loss: 0.6905 - binary_accuracy: 0.5312 - val_loss: 0.6903 - val_binary_accuracy: 0.5316\n",
      "Epoch 4/50\n",
      "25391/25391 [==============================] - 210s 8ms/step - loss: 0.6903 - binary_accuracy: 0.5322 - val_loss: 0.6898 - val_binary_accuracy: 0.5336\n",
      "Epoch 5/50\n",
      "25391/25391 [==============================] - 209s 8ms/step - loss: 0.6901 - binary_accuracy: 0.5327 - val_loss: 0.6904 - val_binary_accuracy: 0.5304\n",
      "Epoch 6/50\n",
      "25391/25391 [==============================] - 208s 8ms/step - loss: 0.6900 - binary_accuracy: 0.5333 - val_loss: 0.6900 - val_binary_accuracy: 0.5326\n",
      "Epoch 7/50\n",
      "25391/25391 [==============================] - 208s 8ms/step - loss: 0.6900 - binary_accuracy: 0.5336 - val_loss: 0.6898 - val_binary_accuracy: 0.5336\n",
      "Epoch 8/50\n",
      "25391/25391 [==============================] - 209s 8ms/step - loss: 0.6899 - binary_accuracy: 0.5336 - val_loss: 0.6897 - val_binary_accuracy: 0.5343\n",
      "Epoch 9/50\n",
      "25391/25391 [==============================] - 208s 8ms/step - loss: 0.6899 - binary_accuracy: 0.5340 - val_loss: 0.6897 - val_binary_accuracy: 0.5340\n",
      "Epoch 10/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6899 - binary_accuracy: 0.5339 - val_loss: 0.6901 - val_binary_accuracy: 0.5319\n",
      "Epoch 11/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6899 - binary_accuracy: 0.5339 - val_loss: 0.6899 - val_binary_accuracy: 0.5330\n",
      "Epoch 12/50\n",
      "25391/25391 [==============================] - 206s 8ms/step - loss: 0.6898 - binary_accuracy: 0.5342 - val_loss: 0.6897 - val_binary_accuracy: 0.5334\n",
      "Epoch 13/50\n",
      "25391/25391 [==============================] - 208s 8ms/step - loss: 0.6899 - binary_accuracy: 0.5342 - val_loss: 0.6898 - val_binary_accuracy: 0.5336\n",
      "Epoch 14/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6898 - binary_accuracy: 0.5341 - val_loss: 0.6897 - val_binary_accuracy: 0.5346\n",
      "Epoch 15/50\n",
      "25391/25391 [==============================] - 206s 8ms/step - loss: 0.6898 - binary_accuracy: 0.5344 - val_loss: 0.6907 - val_binary_accuracy: 0.5274\n",
      "Epoch 16/50\n",
      "25391/25391 [==============================] - 206s 8ms/step - loss: 0.6898 - binary_accuracy: 0.5344 - val_loss: 0.6897 - val_binary_accuracy: 0.5347\n",
      "Epoch 17/50\n",
      "25391/25391 [==============================] - 205s 8ms/step - loss: 0.6898 - binary_accuracy: 0.5344 - val_loss: 0.6900 - val_binary_accuracy: 0.5331\n",
      "Epoch 18/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6898 - binary_accuracy: 0.5345 - val_loss: 0.6897 - val_binary_accuracy: 0.5344\n",
      "Epoch 19/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6898 - binary_accuracy: 0.5346 - val_loss: 0.6898 - val_binary_accuracy: 0.5328\n",
      "Epoch 20/50\n",
      "25391/25391 [==============================] - 205s 8ms/step - loss: 0.6898 - binary_accuracy: 0.5344 - val_loss: 0.6899 - val_binary_accuracy: 0.5323\n",
      "Epoch 21/50\n",
      "25391/25391 [==============================] - 206s 8ms/step - loss: 0.6898 - binary_accuracy: 0.5344 - val_loss: 0.6903 - val_binary_accuracy: 0.5298\n",
      "Epoch 22/50\n",
      "25391/25391 [==============================] - 206s 8ms/step - loss: 0.6897 - binary_accuracy: 0.5345 - val_loss: 0.6897 - val_binary_accuracy: 0.5346\n",
      "Epoch 23/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6897 - binary_accuracy: 0.5346 - val_loss: 0.6895 - val_binary_accuracy: 0.5354\n",
      "Epoch 24/50\n",
      "25391/25391 [==============================] - 205s 8ms/step - loss: 0.6897 - binary_accuracy: 0.5345 - val_loss: 0.6895 - val_binary_accuracy: 0.5355\n",
      "Epoch 25/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6897 - binary_accuracy: 0.5348 - val_loss: 0.6902 - val_binary_accuracy: 0.5326\n",
      "Epoch 26/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6897 - binary_accuracy: 0.5347 - val_loss: 0.6896 - val_binary_accuracy: 0.5350\n",
      "Epoch 27/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6897 - binary_accuracy: 0.5349 - val_loss: 0.6894 - val_binary_accuracy: 0.5353\n",
      "Epoch 28/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6897 - binary_accuracy: 0.5347 - val_loss: 0.6895 - val_binary_accuracy: 0.5354\n",
      "Epoch 29/50\n",
      "25391/25391 [==============================] - 206s 8ms/step - loss: 0.6897 - binary_accuracy: 0.5350 - val_loss: 0.6899 - val_binary_accuracy: 0.5341\n",
      "Epoch 30/50\n",
      "25391/25391 [==============================] - 206s 8ms/step - loss: 0.6897 - binary_accuracy: 0.5349 - val_loss: 0.6900 - val_binary_accuracy: 0.5316\n",
      "Epoch 31/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6897 - binary_accuracy: 0.5346 - val_loss: 0.6897 - val_binary_accuracy: 0.5341\n",
      "Epoch 32/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6896 - binary_accuracy: 0.5349 - val_loss: 0.6896 - val_binary_accuracy: 0.5347\n",
      "Epoch 33/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6897 - binary_accuracy: 0.5349 - val_loss: 0.6896 - val_binary_accuracy: 0.5351\n",
      "Epoch 34/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6896 - binary_accuracy: 0.5351 - val_loss: 0.6896 - val_binary_accuracy: 0.5343\n",
      "Epoch 35/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6896 - binary_accuracy: 0.5350 - val_loss: 0.6895 - val_binary_accuracy: 0.5348\n",
      "Epoch 36/50\n",
      "25391/25391 [==============================] - 206s 8ms/step - loss: 0.6896 - binary_accuracy: 0.5352 - val_loss: 0.6895 - val_binary_accuracy: 0.5347\n",
      "Epoch 37/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6896 - binary_accuracy: 0.5352 - val_loss: 0.6898 - val_binary_accuracy: 0.5331\n",
      "Epoch 38/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6896 - binary_accuracy: 0.5353 - val_loss: 0.6896 - val_binary_accuracy: 0.5348\n",
      "Epoch 39/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6896 - binary_accuracy: 0.5354 - val_loss: 0.6895 - val_binary_accuracy: 0.5351\n",
      "Epoch 40/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6896 - binary_accuracy: 0.5350 - val_loss: 0.6897 - val_binary_accuracy: 0.5342\n",
      "Epoch 41/50\n",
      "25391/25391 [==============================] - 206s 8ms/step - loss: 0.6896 - binary_accuracy: 0.5354 - val_loss: 0.6897 - val_binary_accuracy: 0.5332\n",
      "Epoch 42/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6896 - binary_accuracy: 0.5354 - val_loss: 0.6895 - val_binary_accuracy: 0.5352\n",
      "Epoch 43/50\n",
      "25391/25391 [==============================] - 208s 8ms/step - loss: 0.6896 - binary_accuracy: 0.5354 - val_loss: 0.6896 - val_binary_accuracy: 0.5345\n",
      "Epoch 44/50\n",
      "25391/25391 [==============================] - 208s 8ms/step - loss: 0.6896 - binary_accuracy: 0.5354 - val_loss: 0.6895 - val_binary_accuracy: 0.5342\n",
      "Epoch 45/50\n",
      "25391/25391 [==============================] - 208s 8ms/step - loss: 0.6896 - binary_accuracy: 0.5353 - val_loss: 0.6896 - val_binary_accuracy: 0.5351\n",
      "Epoch 46/50\n",
      "25391/25391 [==============================] - 208s 8ms/step - loss: 0.6896 - binary_accuracy: 0.5352 - val_loss: 0.6897 - val_binary_accuracy: 0.5337\n",
      "Epoch 47/50\n",
      "25391/25391 [==============================] - 210s 8ms/step - loss: 0.6895 - binary_accuracy: 0.5355 - val_loss: 0.6895 - val_binary_accuracy: 0.5348\n",
      "Epoch 48/50\n",
      "25391/25391 [==============================] - 208s 8ms/step - loss: 0.6896 - binary_accuracy: 0.5354 - val_loss: 0.6894 - val_binary_accuracy: 0.5352\n",
      "Epoch 49/50\n",
      "25391/25391 [==============================] - 208s 8ms/step - loss: 0.6896 - binary_accuracy: 0.5352 - val_loss: 0.6895 - val_binary_accuracy: 0.5352\n",
      "Epoch 50/50\n",
      "25391/25391 [==============================] - 184s 7ms/step - loss: 0.6895 - binary_accuracy: 0.5352 - val_loss: 0.6895 - val_binary_accuracy: 0.5353\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "learning_rate = 0.001  # Learning rate\n",
    "epochs = 50  # Number of training epochs\n",
    "es_patience = 10  # Patience for early stopping\n",
    "batch_size = 256  # Batch size\n",
    "\n",
    "# Data loaders\n",
    "loader_tr = BatchLoader(data_tr, batch_size=batch_size, epochs=epochs)\n",
    "loader_va = BatchLoader(data_va, batch_size=batch_size)\n",
    "loader_te = BatchLoader(data_te, batch_size=batch_size)\n",
    "\n",
    "# Build model\n",
    "class Net_1_1(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(19, activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.dense = Dense(d.n_labels, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        # x.shape is [n_batches, 5, n_ features]\n",
    "        # a.shape is [n_batches, 5, 5]\n",
    "\n",
    "        x = self.conv1([x, a])\n",
    "        # x.shape is [n_batches, 5, channels] where I have set channels = features (20)\n",
    "\n",
    "        x =self.flatten(x)\n",
    "        # x.shape is [n_batches, 5*channels]\n",
    "\n",
    "        x = self.dense(x)\n",
    "        # output.shape is [n_batches, 1]\n",
    "        \n",
    "        return x\n",
    "\n",
    "model_1_1 = Net_1_1()\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "loss_fn = BinaryCrossentropy()\n",
    "model_1_1.compile(optimizer=optimizer, loss=loss_fn, metrics=['binary_accuracy'])\n",
    "\n",
    "fit_log_1_1 = model_1_1.fit(loader_tr.load(), steps_per_epoch=loader_tr.steps_per_epoch, epochs=epochs, validation_data=loader_va.load(), validation_steps=loader_va.steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "Training",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          0.525854766368866,
          0.5300338268280029,
          0.5312279462814331,
          0.5322333574295044,
          0.5327252149581909,
          0.5332916378974915,
          0.5336098074913025,
          0.5336436629295349,
          0.5340373516082764,
          0.5339007377624512,
          0.533860445022583,
          0.5341867208480835,
          0.5341810584068298,
          0.5341396331787109,
          0.5343518257141113,
          0.5344443917274475,
          0.5344108939170837,
          0.5344544053077698,
          0.5346084237098694,
          0.5344300866127014,
          0.5343865752220154,
          0.5344935059547424,
          0.5346388816833496,
          0.5345361232757568,
          0.5347996354103088,
          0.5346984267234802,
          0.5348730087280273,
          0.5347374677658081,
          0.5350073575973511,
          0.53488689661026,
          0.5346271991729736,
          0.5348910093307495,
          0.5348761081695557,
          0.535051167011261,
          0.5349907279014587,
          0.5352202653884888,
          0.5352444052696228,
          0.5353350043296814,
          0.5353870391845703,
          0.5350465774536133,
          0.535365641117096,
          0.5354182720184326,
          0.5353610515594482,
          0.5353760719299316,
          0.5352621078491211,
          0.5351936221122742,
          0.5354653596878052,
          0.5353714823722839,
          0.5352067351341248,
          0.5352413058280945
         ]
        },
        {
         "mode": "lines",
         "name": "Validation",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          0.5317333340644836,
          0.5332397818565369,
          0.5316336750984192,
          0.5336416363716125,
          0.5303671956062317,
          0.5326004028320312,
          0.5335702300071716,
          0.5342952013015747,
          0.5340194702148438,
          0.531863808631897,
          0.5329813361167908,
          0.533384382724762,
          0.5336422324180603,
          0.5346453189849854,
          0.5274244546890259,
          0.5346582531929016,
          0.5331419706344604,
          0.5343763828277588,
          0.5327567458152771,
          0.532348096370697,
          0.5297831892967224,
          0.5345954895019531,
          0.5353536009788513,
          0.5354539155960083,
          0.5326133370399475,
          0.535043478012085,
          0.5353283882141113,
          0.5353505611419678,
          0.534148097038269,
          0.531639814376831,
          0.534144401550293,
          0.5347025394439697,
          0.5350582599639893,
          0.5342982411384583,
          0.534756064414978,
          0.5347093343734741,
          0.5331247448921204,
          0.5347720980644226,
          0.5351351499557495,
          0.5341991782188416,
          0.5332397818565369,
          0.5352367162704468,
          0.5345271825790405,
          0.5342336297035217,
          0.5351486802101135,
          0.5336668491363525,
          0.5348262190818787,
          0.5351800918579102,
          0.5352028608322144,
          0.5352687239646912
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "scatter": [
           {
            "type": "scatter"
           }
          ]
         }
        },
        "xaxis": {
         "dtick": 1,
         "tick0": 0,
         "title": {
          "text": "Epochs"
         }
        },
        "yaxis": {
         "title": {
          "text": "Accuracy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "epochs = list(range(1,len(fit_log_1_1.history['binary_accuracy'])+1))\n",
    "training_accuracy = fit_log_1_1.history['binary_accuracy']\n",
    "validation_accuracy = fit_log_1_1.history['val_binary_accuracy']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=training_accuracy,\n",
    "    mode='lines',\n",
    "    name='Training'))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=validation_accuracy,\n",
    "    mode='lines',\n",
    "    name='Validation'))\n",
    "fig.update_layout(\n",
    "    template='none',\n",
    "    xaxis_title='Epochs',\n",
    "    yaxis_title=\"Accuracy\")\n",
    "fig.update_xaxes(tick0=0, dtick=1)\n",
    "# fig.update_yaxes(range=[0.5,1])\n",
    "fig.show()\n",
    "fig.write_image(f'../images/model_1_1_accuracy.png', scale=5)\n",
    "pd.DataFrame({'epoch': epochs, 'training_accuracy':training_accuracy, 'validation_accuracy':validation_accuracy}).to_csv('../images/model_1_1_accuracy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dropout_2_layer_call_fn, dropout_2_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://956608be-fc57-4333-aef7-11622328db6f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://956608be-fc57-4333-aef7-11622328db6f/assets\n",
      "WARNING:absl:Found untraced functions such as dropout_2_layer_call_fn, dropout_2_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://597eca29-d923-4855-b598-ef1201bbb3d0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://597eca29-d923-4855-b598-ef1201bbb3d0/assets\n"
     ]
    }
   ],
   "source": [
    "filehandler = open(f'../models/fit_log_1_1.pkl','wb')\n",
    "pickle.dump(fit_log_1_1, filehandler)\n",
    "filehandler = open(f'../models/model_1_1.pkl','wb')\n",
    "pickle.dump(model_1_1, filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1.2 Average Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25391/25391 [==============================] - 138s 5ms/step - loss: 0.6931 - binary_accuracy: 0.5156 - val_loss: 0.6914 - val_binary_accuracy: 0.5236\n",
      "Epoch 2/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6918 - binary_accuracy: 0.5214 - val_loss: 0.6915 - val_binary_accuracy: 0.5231\n",
      "Epoch 3/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6914 - binary_accuracy: 0.5237 - val_loss: 0.6911 - val_binary_accuracy: 0.5255\n",
      "Epoch 4/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6912 - binary_accuracy: 0.5249 - val_loss: 0.6909 - val_binary_accuracy: 0.5273\n",
      "Epoch 5/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6911 - binary_accuracy: 0.5260 - val_loss: 0.6908 - val_binary_accuracy: 0.5276\n",
      "Epoch 6/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6910 - binary_accuracy: 0.5264 - val_loss: 0.6910 - val_binary_accuracy: 0.5265\n",
      "Epoch 7/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6909 - binary_accuracy: 0.5270 - val_loss: 0.6907 - val_binary_accuracy: 0.5278\n",
      "Epoch 8/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6909 - binary_accuracy: 0.5274 - val_loss: 0.6909 - val_binary_accuracy: 0.5266\n",
      "Epoch 9/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5274 - val_loss: 0.6908 - val_binary_accuracy: 0.5278\n",
      "Epoch 10/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5276 - val_loss: 0.6908 - val_binary_accuracy: 0.5272\n",
      "Epoch 11/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5278 - val_loss: 0.6908 - val_binary_accuracy: 0.5274\n",
      "Epoch 12/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5280 - val_loss: 0.6908 - val_binary_accuracy: 0.5270\n",
      "Epoch 13/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6907 - binary_accuracy: 0.5281 - val_loss: 0.6907 - val_binary_accuracy: 0.5280\n",
      "Epoch 14/50\n",
      "25391/25391 [==============================] - 133s 5ms/step - loss: 0.6907 - binary_accuracy: 0.5283 - val_loss: 0.6907 - val_binary_accuracy: 0.5281\n",
      "Epoch 15/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6907 - binary_accuracy: 0.5283 - val_loss: 0.6906 - val_binary_accuracy: 0.5286\n",
      "Epoch 16/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6907 - binary_accuracy: 0.5285 - val_loss: 0.6906 - val_binary_accuracy: 0.5284\n",
      "Epoch 17/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6906 - binary_accuracy: 0.5286 - val_loss: 0.6907 - val_binary_accuracy: 0.5284\n",
      "Epoch 18/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6906 - binary_accuracy: 0.5288 - val_loss: 0.6907 - val_binary_accuracy: 0.5287\n",
      "Epoch 19/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6906 - binary_accuracy: 0.5289 - val_loss: 0.6905 - val_binary_accuracy: 0.5290\n",
      "Epoch 20/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6906 - binary_accuracy: 0.5290 - val_loss: 0.6904 - val_binary_accuracy: 0.5292\n",
      "Epoch 21/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6905 - binary_accuracy: 0.5291 - val_loss: 0.6907 - val_binary_accuracy: 0.5286\n",
      "Epoch 22/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6905 - binary_accuracy: 0.5291 - val_loss: 0.6906 - val_binary_accuracy: 0.5287\n",
      "Epoch 23/50\n",
      "25391/25391 [==============================] - 133s 5ms/step - loss: 0.6905 - binary_accuracy: 0.5292 - val_loss: 0.6905 - val_binary_accuracy: 0.5289\n",
      "Epoch 24/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6905 - binary_accuracy: 0.5293 - val_loss: 0.6907 - val_binary_accuracy: 0.5278\n",
      "Epoch 25/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6905 - binary_accuracy: 0.5294 - val_loss: 0.6904 - val_binary_accuracy: 0.5295\n",
      "Epoch 26/50\n",
      "25391/25391 [==============================] - 133s 5ms/step - loss: 0.6905 - binary_accuracy: 0.5294 - val_loss: 0.6906 - val_binary_accuracy: 0.5285\n",
      "Epoch 27/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6905 - binary_accuracy: 0.5294 - val_loss: 0.6907 - val_binary_accuracy: 0.5279\n",
      "Epoch 28/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6905 - binary_accuracy: 0.5295 - val_loss: 0.6906 - val_binary_accuracy: 0.5283\n",
      "Epoch 29/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6905 - binary_accuracy: 0.5296 - val_loss: 0.6904 - val_binary_accuracy: 0.5293\n",
      "Epoch 30/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6905 - binary_accuracy: 0.5294 - val_loss: 0.6904 - val_binary_accuracy: 0.5293\n",
      "Epoch 31/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6904 - binary_accuracy: 0.5295 - val_loss: 0.6904 - val_binary_accuracy: 0.5296\n",
      "Epoch 32/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6904 - binary_accuracy: 0.5296 - val_loss: 0.6905 - val_binary_accuracy: 0.5290\n",
      "Epoch 33/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6904 - binary_accuracy: 0.5297 - val_loss: 0.6906 - val_binary_accuracy: 0.5284\n",
      "Epoch 34/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6904 - binary_accuracy: 0.5298 - val_loss: 0.6909 - val_binary_accuracy: 0.5271\n",
      "Epoch 35/50\n",
      "25391/25391 [==============================] - 132s 5ms/step - loss: 0.6904 - binary_accuracy: 0.5297 - val_loss: 0.6905 - val_binary_accuracy: 0.5291\n",
      "Epoch 36/50\n",
      "25391/25391 [==============================] - 143s 6ms/step - loss: 0.6904 - binary_accuracy: 0.5297 - val_loss: 0.6906 - val_binary_accuracy: 0.5284\n",
      "Epoch 37/50\n",
      "25391/25391 [==============================] - 144s 6ms/step - loss: 0.6904 - binary_accuracy: 0.5297 - val_loss: 0.6904 - val_binary_accuracy: 0.5296\n",
      "Epoch 38/50\n",
      "25391/25391 [==============================] - 144s 6ms/step - loss: 0.6904 - binary_accuracy: 0.5299 - val_loss: 0.6905 - val_binary_accuracy: 0.5293\n",
      "Epoch 39/50\n",
      "25391/25391 [==============================] - 144s 6ms/step - loss: 0.6904 - binary_accuracy: 0.5297 - val_loss: 0.6905 - val_binary_accuracy: 0.5289\n",
      "Epoch 40/50\n",
      "25391/25391 [==============================] - 143s 6ms/step - loss: 0.6904 - binary_accuracy: 0.5299 - val_loss: 0.6904 - val_binary_accuracy: 0.5290\n",
      "Epoch 41/50\n",
      "25391/25391 [==============================] - 144s 6ms/step - loss: 0.6904 - binary_accuracy: 0.5299 - val_loss: 0.6904 - val_binary_accuracy: 0.5294\n",
      "Epoch 42/50\n",
      "25391/25391 [==============================] - 142s 6ms/step - loss: 0.6904 - binary_accuracy: 0.5299 - val_loss: 0.6903 - val_binary_accuracy: 0.5297\n",
      "Epoch 43/50\n",
      "25391/25391 [==============================] - 137s 5ms/step - loss: 0.6904 - binary_accuracy: 0.5299 - val_loss: 0.6903 - val_binary_accuracy: 0.5298\n",
      "Epoch 44/50\n",
      "25391/25391 [==============================] - 137s 5ms/step - loss: 0.6904 - binary_accuracy: 0.5297 - val_loss: 0.6904 - val_binary_accuracy: 0.5295\n",
      "Epoch 45/50\n",
      "25391/25391 [==============================] - 139s 5ms/step - loss: 0.6904 - binary_accuracy: 0.5299 - val_loss: 0.6903 - val_binary_accuracy: 0.5298\n",
      "Epoch 46/50\n",
      "25391/25391 [==============================] - 136s 5ms/step - loss: 0.6904 - binary_accuracy: 0.5300 - val_loss: 0.6905 - val_binary_accuracy: 0.5288\n",
      "Epoch 47/50\n",
      "25391/25391 [==============================] - 129s 5ms/step - loss: 0.6904 - binary_accuracy: 0.5301 - val_loss: 0.6908 - val_binary_accuracy: 0.5279\n",
      "Epoch 48/50\n",
      "25391/25391 [==============================] - 128s 5ms/step - loss: 0.6904 - binary_accuracy: 0.5299 - val_loss: 0.6904 - val_binary_accuracy: 0.5300\n",
      "Epoch 49/50\n",
      "25391/25391 [==============================] - 129s 5ms/step - loss: 0.6904 - binary_accuracy: 0.5300 - val_loss: 0.6905 - val_binary_accuracy: 0.5288\n",
      "Epoch 50/50\n",
      "25391/25391 [==============================] - 110s 4ms/step - loss: 0.6904 - binary_accuracy: 0.5299 - val_loss: 0.6903 - val_binary_accuracy: 0.5295\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "learning_rate = 0.001  # Learning rate\n",
    "epochs = 50  # Number of training epochs\n",
    "es_patience = 10  # Patience for early stopping\n",
    "batch_size = 256  # Batch size\n",
    "\n",
    "# Data loaders\n",
    "loader_tr = BatchLoader(data_tr, batch_size=batch_size, epochs=epochs)\n",
    "loader_va = BatchLoader(data_va, batch_size=batch_size)\n",
    "loader_te = BatchLoader(data_te, batch_size=batch_size)\n",
    "\n",
    "# Build model\n",
    "class Net_1_2(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(19, activation='relu')\n",
    "        self.pool1 = GlobalAvgPool()\n",
    "        self.flatten = Flatten()\n",
    "        self.dense = Dense(d.n_labels, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        # x.shape is [n_batches, 5, n_ features]\n",
    "        # a.shape is [n_batches, 5, 5]\n",
    "\n",
    "        x = self.conv1([x, a])\n",
    "        # x.shape is [n_batches, 5, channels] where I have set channels = features (20)\n",
    "\n",
    "        x = self.pool1(x)\n",
    "        # x.shape is [n_batches, channels]\n",
    "\n",
    "        x = self.dense(x)\n",
    "        # output.shape is [n_batches, 1]\n",
    "        \n",
    "        return x\n",
    "\n",
    "model_1_2 = Net_1_2()\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "loss_fn = BinaryCrossentropy()\n",
    "model_1_2.compile(optimizer=optimizer, loss=loss_fn, metrics=['binary_accuracy'])\n",
    "\n",
    "fit_log_1_2 = model_1_2.fit(loader_tr.load(), steps_per_epoch=loader_tr.steps_per_epoch, epochs=epochs, validation_data=loader_va.load(), validation_steps=loader_va.steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "Training",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          0.5155901908874512,
          0.5214194059371948,
          0.5237383246421814,
          0.524864137172699,
          0.5260355472564697,
          0.5263766050338745,
          0.5270061492919922,
          0.5273600220680237,
          0.5274381637573242,
          0.5276026129722595,
          0.5277860164642334,
          0.5280147790908813,
          0.5281271934509277,
          0.5283350944519043,
          0.5283453464508057,
          0.528456449508667,
          0.5286087393760681,
          0.5288398265838623,
          0.5289498567581177,
          0.5289819836616516,
          0.5291092395782471,
          0.5291329026222229,
          0.5292162895202637,
          0.5293304324150085,
          0.5293729305267334,
          0.5294148921966553,
          0.529391348361969,
          0.5295382738113403,
          0.5296306014060974,
          0.5294478535652161,
          0.5295345783233643,
          0.529573380947113,
          0.5296531915664673,
          0.5297770500183105,
          0.5297209024429321,
          0.5297383069992065,
          0.5296595096588135,
          0.5298698544502258,
          0.529678463935852,
          0.5299399495124817,
          0.5299462676048279,
          0.5298996567726135,
          0.5298750400543213,
          0.5297098159790039,
          0.5299366116523743,
          0.5300333499908447,
          0.5300629138946533,
          0.529914915561676,
          0.530042290687561,
          0.52989661693573
         ]
        },
        {
         "mode": "lines",
         "name": "Validation",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          0.5235629081726074,
          0.5230656862258911,
          0.5254570841789246,
          0.5272878408432007,
          0.5276238322257996,
          0.5265111923217773,
          0.5278139710426331,
          0.5265979766845703,
          0.5277770757675171,
          0.5272096991539001,
          0.5274466276168823,
          0.5269752144813538,
          0.528002917766571,
          0.5281106233596802,
          0.5285573601722717,
          0.528393030166626,
          0.5284035205841064,
          0.5287235379219055,
          0.5290176868438721,
          0.5292072296142578,
          0.5285758376121521,
          0.5287216901779175,
          0.5289161205291748,
          0.527808427810669,
          0.5295462608337402,
          0.5285155177116394,
          0.5279235243797302,
          0.5282970666885376,
          0.5293388962745667,
          0.5292589068412781,
          0.5296213626861572,
          0.5289856791496277,
          0.5284238457679749,
          0.5271062850952148,
          0.5291290283203125,
          0.5284084677696228,
          0.5295690298080444,
          0.5292865633964539,
          0.528938889503479,
          0.529041051864624,
          0.5294219851493835,
          0.5296952128410339,
          0.529836118221283,
          0.5294588804244995,
          0.5298318266868591,
          0.5287530422210693,
          0.5278693437576294,
          0.5299838185310364,
          0.5288379788398743,
          0.5295284390449524
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "scatter": [
           {
            "type": "scatter"
           }
          ]
         }
        },
        "xaxis": {
         "dtick": 1,
         "tick0": 0,
         "title": {
          "text": "Epochs"
         }
        },
        "yaxis": {
         "title": {
          "text": "Accuracy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "epochs = list(range(1,len(fit_log_1_2.history['binary_accuracy'])+1))\n",
    "training_accuracy = fit_log_1_2.history['binary_accuracy']\n",
    "validation_accuracy = fit_log_1_2.history['val_binary_accuracy']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=training_accuracy,\n",
    "    mode='lines',\n",
    "    name='Training'))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=validation_accuracy,\n",
    "    mode='lines',\n",
    "    name='Validation'))\n",
    "fig.update_layout(\n",
    "    template='none',\n",
    "    xaxis_title='Epochs',\n",
    "    yaxis_title=\"Accuracy\")\n",
    "fig.update_xaxes(tick0=0, dtick=1)\n",
    "# fig.update_yaxes(range=[0.5,1])\n",
    "fig.show()\n",
    "fig.write_image(f'../images/model_1_2_accuracy.png', scale=5)\n",
    "pd.DataFrame({'epoch': epochs, 'training_accuracy':training_accuracy, 'validation_accuracy':validation_accuracy}).to_csv('../images/model_1_2_accuracy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.reshaping.flatten.Flatten object at 0x000002759D939030>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.reshaping.flatten.Flatten object at 0x000002759D939030>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://29ccb6c4-b7a8-4122-a360-a938ff6d948a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://29ccb6c4-b7a8-4122-a360-a938ff6d948a/assets\n",
      "c:\\Users\\nick_\\.virtualenvs\\dotaprediction-eZ2WDOkz\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning:\n",
      "\n",
      "Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.reshaping.flatten.Flatten object at 0x000002759D939030>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.reshaping.flatten.Flatten object at 0x000002759D939030>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://59ee2602-97ad-4795-9064-2876f2390e32/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://59ee2602-97ad-4795-9064-2876f2390e32/assets\n",
      "c:\\Users\\nick_\\.virtualenvs\\dotaprediction-eZ2WDOkz\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning:\n",
      "\n",
      "Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filehandler = open(f'../models/fit_log_1_2.pkl','wb')\n",
    "pickle.dump(fit_log_1_2, filehandler)\n",
    "filehandler = open(f'../models/model_1_2.pkl','wb')\n",
    "pickle.dump(model_1_2, filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1.3 - Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25391/25391 [==============================] - 163s 6ms/step - loss: 0.6929 - binary_accuracy: 0.5158 - val_loss: 0.6918 - val_binary_accuracy: 0.5203\n",
      "Epoch 2/50\n",
      "25391/25391 [==============================] - 155s 6ms/step - loss: 0.6917 - binary_accuracy: 0.5218 - val_loss: 0.6912 - val_binary_accuracy: 0.5251\n",
      "Epoch 3/50\n",
      "25391/25391 [==============================] - 159s 6ms/step - loss: 0.6913 - binary_accuracy: 0.5244 - val_loss: 0.6912 - val_binary_accuracy: 0.5258\n",
      "Epoch 4/50\n",
      "25391/25391 [==============================] - 153s 6ms/step - loss: 0.6911 - binary_accuracy: 0.5256 - val_loss: 0.6911 - val_binary_accuracy: 0.5252\n",
      "Epoch 5/50\n",
      "25391/25391 [==============================] - 157s 6ms/step - loss: 0.6910 - binary_accuracy: 0.5263 - val_loss: 0.6912 - val_binary_accuracy: 0.5244\n",
      "Epoch 6/50\n",
      "25391/25391 [==============================] - 157s 6ms/step - loss: 0.6909 - binary_accuracy: 0.5268 - val_loss: 0.6913 - val_binary_accuracy: 0.5248\n",
      "Epoch 7/50\n",
      "25391/25391 [==============================] - 144s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5272 - val_loss: 0.6908 - val_binary_accuracy: 0.5271\n",
      "Epoch 8/50\n",
      "25391/25391 [==============================] - 157s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5276 - val_loss: 0.6910 - val_binary_accuracy: 0.5267\n",
      "Epoch 9/50\n",
      "25391/25391 [==============================] - 161s 6ms/step - loss: 0.6907 - binary_accuracy: 0.5277 - val_loss: 0.6908 - val_binary_accuracy: 0.5276\n",
      "Epoch 10/50\n",
      "25391/25391 [==============================] - 158s 6ms/step - loss: 0.6907 - binary_accuracy: 0.5279 - val_loss: 0.6913 - val_binary_accuracy: 0.5244\n",
      "Epoch 11/50\n",
      "25391/25391 [==============================] - 151s 6ms/step - loss: 0.6907 - binary_accuracy: 0.5281 - val_loss: 0.6907 - val_binary_accuracy: 0.5278\n",
      "Epoch 12/50\n",
      "25391/25391 [==============================] - 156s 6ms/step - loss: 0.6907 - binary_accuracy: 0.5284 - val_loss: 0.6907 - val_binary_accuracy: 0.5270\n",
      "Epoch 13/50\n",
      "25391/25391 [==============================] - 155s 6ms/step - loss: 0.6907 - binary_accuracy: 0.5283 - val_loss: 0.6905 - val_binary_accuracy: 0.5284\n",
      "Epoch 14/50\n",
      "25391/25391 [==============================] - 152s 6ms/step - loss: 0.6906 - binary_accuracy: 0.5286 - val_loss: 0.6914 - val_binary_accuracy: 0.5240\n",
      "Epoch 15/50\n",
      "25391/25391 [==============================] - 147s 6ms/step - loss: 0.6906 - binary_accuracy: 0.5287 - val_loss: 0.6906 - val_binary_accuracy: 0.5282\n",
      "Epoch 16/50\n",
      "25391/25391 [==============================] - 149s 6ms/step - loss: 0.6906 - binary_accuracy: 0.5285 - val_loss: 0.6905 - val_binary_accuracy: 0.5290\n",
      "Epoch 17/50\n",
      "25391/25391 [==============================] - 148s 6ms/step - loss: 0.6906 - binary_accuracy: 0.5289 - val_loss: 0.6906 - val_binary_accuracy: 0.5279\n",
      "Epoch 18/50\n",
      "25391/25391 [==============================] - 151s 6ms/step - loss: 0.6906 - binary_accuracy: 0.5288 - val_loss: 0.6908 - val_binary_accuracy: 0.5273\n",
      "Epoch 19/50\n",
      "25391/25391 [==============================] - 141s 6ms/step - loss: 0.6906 - binary_accuracy: 0.5290 - val_loss: 0.6907 - val_binary_accuracy: 0.5276\n",
      "Epoch 20/50\n",
      "25391/25391 [==============================] - 142s 6ms/step - loss: 0.6906 - binary_accuracy: 0.5288 - val_loss: 0.6906 - val_binary_accuracy: 0.5281\n",
      "Epoch 21/50\n",
      "25391/25391 [==============================] - 141s 6ms/step - loss: 0.6906 - binary_accuracy: 0.5289 - val_loss: 0.6905 - val_binary_accuracy: 0.5295\n",
      "Epoch 22/50\n",
      "25391/25391 [==============================] - 142s 6ms/step - loss: 0.6905 - binary_accuracy: 0.5292 - val_loss: 0.6906 - val_binary_accuracy: 0.5282\n",
      "Epoch 23/50\n",
      "25391/25391 [==============================] - 144s 6ms/step - loss: 0.6905 - binary_accuracy: 0.5291 - val_loss: 0.6907 - val_binary_accuracy: 0.5281\n",
      "Epoch 24/50\n",
      "25391/25391 [==============================] - 147s 6ms/step - loss: 0.6905 - binary_accuracy: 0.5292 - val_loss: 0.6906 - val_binary_accuracy: 0.5283\n",
      "Epoch 25/50\n",
      "25391/25391 [==============================] - 154s 6ms/step - loss: 0.6905 - binary_accuracy: 0.5291 - val_loss: 0.6905 - val_binary_accuracy: 0.5291\n",
      "Epoch 26/50\n",
      "25391/25391 [==============================] - 141s 6ms/step - loss: 0.6905 - binary_accuracy: 0.5293 - val_loss: 0.6904 - val_binary_accuracy: 0.5291\n",
      "Epoch 27/50\n",
      "25391/25391 [==============================] - 139s 5ms/step - loss: 0.6905 - binary_accuracy: 0.5293 - val_loss: 0.6906 - val_binary_accuracy: 0.5285\n",
      "Epoch 28/50\n",
      "25391/25391 [==============================] - 152s 6ms/step - loss: 0.6905 - binary_accuracy: 0.5294 - val_loss: 0.6905 - val_binary_accuracy: 0.5289\n",
      "Epoch 29/50\n",
      "25391/25391 [==============================] - 146s 6ms/step - loss: 0.6905 - binary_accuracy: 0.5293 - val_loss: 0.6908 - val_binary_accuracy: 0.5272\n",
      "Epoch 30/50\n",
      "25391/25391 [==============================] - 144s 6ms/step - loss: 0.6905 - binary_accuracy: 0.5291 - val_loss: 0.6905 - val_binary_accuracy: 0.5293\n",
      "Epoch 31/50\n",
      "25391/25391 [==============================] - 150s 6ms/step - loss: 0.6905 - binary_accuracy: 0.5292 - val_loss: 0.6907 - val_binary_accuracy: 0.5281\n",
      "Epoch 32/50\n",
      "25391/25391 [==============================] - 142s 6ms/step - loss: 0.6905 - binary_accuracy: 0.5293 - val_loss: 0.6907 - val_binary_accuracy: 0.5283\n",
      "Epoch 33/50\n",
      "25391/25391 [==============================] - 142s 6ms/step - loss: 0.6905 - binary_accuracy: 0.5293 - val_loss: 0.6904 - val_binary_accuracy: 0.5294\n",
      "Epoch 34/50\n",
      "25391/25391 [==============================] - 143s 6ms/step - loss: 0.6905 - binary_accuracy: 0.5295 - val_loss: 0.6905 - val_binary_accuracy: 0.5287\n",
      "Epoch 35/50\n",
      "25391/25391 [==============================] - 144s 6ms/step - loss: 0.6905 - binary_accuracy: 0.5294 - val_loss: 0.6909 - val_binary_accuracy: 0.5270\n",
      "Epoch 36/50\n",
      "25391/25391 [==============================] - 152s 6ms/step - loss: 0.6905 - binary_accuracy: 0.5295 - val_loss: 0.6907 - val_binary_accuracy: 0.5280\n",
      "Epoch 37/50\n",
      "25391/25391 [==============================] - 154s 6ms/step - loss: 0.6905 - binary_accuracy: 0.5293 - val_loss: 0.6905 - val_binary_accuracy: 0.5292\n",
      "Epoch 38/50\n",
      "25391/25391 [==============================] - 149s 6ms/step - loss: 0.6905 - binary_accuracy: 0.5296 - val_loss: 0.6905 - val_binary_accuracy: 0.5288\n",
      "Epoch 39/50\n",
      "25391/25391 [==============================] - 146s 6ms/step - loss: 0.6905 - binary_accuracy: 0.5294 - val_loss: 0.6904 - val_binary_accuracy: 0.5293\n",
      "Epoch 40/50\n",
      "25391/25391 [==============================] - 158s 6ms/step - loss: 0.6905 - binary_accuracy: 0.5297 - val_loss: 0.6904 - val_binary_accuracy: 0.5291\n",
      "Epoch 41/50\n",
      "25391/25391 [==============================] - 153s 6ms/step - loss: 0.6904 - binary_accuracy: 0.5296 - val_loss: 0.6907 - val_binary_accuracy: 0.5271\n",
      "Epoch 42/50\n",
      "25391/25391 [==============================] - 156s 6ms/step - loss: 0.6904 - binary_accuracy: 0.5294 - val_loss: 0.6907 - val_binary_accuracy: 0.5278\n",
      "Epoch 43/50\n",
      "25391/25391 [==============================] - 138s 5ms/step - loss: 0.6904 - binary_accuracy: 0.5298 - val_loss: 0.6905 - val_binary_accuracy: 0.5289\n",
      "Epoch 44/50\n",
      "25391/25391 [==============================] - 139s 5ms/step - loss: 0.6904 - binary_accuracy: 0.5296 - val_loss: 0.6910 - val_binary_accuracy: 0.5262\n",
      "Epoch 45/50\n",
      "25391/25391 [==============================] - 139s 5ms/step - loss: 0.6904 - binary_accuracy: 0.5296 - val_loss: 0.6905 - val_binary_accuracy: 0.5291\n",
      "Epoch 46/50\n",
      "25391/25391 [==============================] - 141s 6ms/step - loss: 0.6904 - binary_accuracy: 0.5296 - val_loss: 0.6904 - val_binary_accuracy: 0.5292\n",
      "Epoch 47/50\n",
      "25391/25391 [==============================] - 160s 6ms/step - loss: 0.6904 - binary_accuracy: 0.5297 - val_loss: 0.6905 - val_binary_accuracy: 0.5291\n",
      "Epoch 48/50\n",
      "25391/25391 [==============================] - 151s 6ms/step - loss: 0.6904 - binary_accuracy: 0.5297 - val_loss: 0.6907 - val_binary_accuracy: 0.5283\n",
      "Epoch 49/50\n",
      "25391/25391 [==============================] - 146s 6ms/step - loss: 0.6904 - binary_accuracy: 0.5298 - val_loss: 0.6906 - val_binary_accuracy: 0.5283\n",
      "Epoch 50/50\n",
      "25391/25391 [==============================] - 127s 5ms/step - loss: 0.6904 - binary_accuracy: 0.5298 - val_loss: 0.6903 - val_binary_accuracy: 0.5300\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "learning_rate = 0.001  # Learning rate\n",
    "epochs = 50  # Number of training epochs\n",
    "es_patience = 10  # Patience for early stopping\n",
    "batch_size = 256  # Batch size\n",
    "\n",
    "# Data loaders\n",
    "loader_tr = BatchLoader(data_tr, batch_size=batch_size, epochs=epochs)\n",
    "loader_va = BatchLoader(data_va, batch_size=batch_size)\n",
    "loader_te = BatchLoader(data_te, batch_size=batch_size)\n",
    "\n",
    "# Build model\n",
    "class Net_1_3(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(19, activation='relu')\n",
    "        self.pool1 = GlobalMaxPool()\n",
    "        self.dense = Dense(d.n_labels, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        # x.shape is [n_batches, 5, n_ features]\n",
    "        # a.shape is [n_batches, 5, 5]\n",
    "\n",
    "        x = self.conv1([x, a])\n",
    "        # x.shape is [n_batches, 5, channels] where I have set channels = features (20)\n",
    "\n",
    "        x = self.pool1(x)\n",
    "        # x.shape is [n_batches, channels]\n",
    "\n",
    "        x = self.dense(x)\n",
    "        # output.shape is [n_batches, 1]\n",
    "        \n",
    "        return x\n",
    "\n",
    "model_1_3 = Net_1_3()\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "loss_fn = BinaryCrossentropy()\n",
    "model_1_3.compile(optimizer=optimizer, loss=loss_fn, metrics=['binary_accuracy'])\n",
    "\n",
    "fit_log_1_3 = model_1_3.fit(loader_tr.load(), steps_per_epoch=loader_tr.steps_per_epoch, epochs=epochs, validation_data=loader_va.load(), validation_steps=loader_va.steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "Training",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          0.5157554745674133,
          0.5218374133110046,
          0.5243944525718689,
          0.5255738496780396,
          0.52625972032547,
          0.5268380045890808,
          0.5272465944290161,
          0.5276222825050354,
          0.5276646018028259,
          0.5278898477554321,
          0.5281221270561218,
          0.528383195400238,
          0.528321385383606,
          0.5285589098930359,
          0.5286687612533569,
          0.5285072326660156,
          0.5288589000701904,
          0.5287659764289856,
          0.5289753675460815,
          0.5287741422653198,
          0.5289273858070374,
          0.5291558504104614,
          0.5291162729263306,
          0.5291681289672852,
          0.5290703177452087,
          0.5293070673942566,
          0.5293055176734924,
          0.5294346213340759,
          0.5292711853981018,
          0.5291264653205872,
          0.5292479991912842,
          0.529283344745636,
          0.5293465852737427,
          0.5295072197914124,
          0.5293979644775391,
          0.5295101404190063,
          0.5293406248092651,
          0.5295838117599487,
          0.5293707251548767,
          0.5296787619590759,
          0.5295842885971069,
          0.5294492244720459,
          0.5298246145248413,
          0.5296033620834351,
          0.5296345949172974,
          0.5295888781547546,
          0.5297386050224304,
          0.5297161340713501,
          0.5298029184341431,
          0.529813826084137
         ]
        },
        {
         "mode": "lines",
         "name": "Validation",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          0.5202509760856628,
          0.5251487493515015,
          0.5257764458656311,
          0.5252262949943542,
          0.5244398713111877,
          0.5247856974601746,
          0.5270509123802185,
          0.5267149209976196,
          0.5276158452033997,
          0.5243635177612305,
          0.5278189182281494,
          0.527015209197998,
          0.5283610820770264,
          0.523959219455719,
          0.5281623005867004,
          0.5289776921272278,
          0.5278705954551697,
          0.5272533893585205,
          0.5276035070419312,
          0.5281339883804321,
          0.5295345783233643,
          0.5281678438186646,
          0.5280638337135315,
          0.5283383131027222,
          0.5290736556053162,
          0.5291149020195007,
          0.5284909009933472,
          0.5289093852043152,
          0.5271795392036438,
          0.5292896628379822,
          0.5280619859695435,
          0.5282545685768127,
          0.5294379591941833,
          0.5286773443222046,
          0.5270189046859741,
          0.5279727578163147,
          0.529153048992157,
          0.5288478136062622,
          0.5293013453483582,
          0.5291327238082886,
          0.5271351933479309,
          0.5278306007385254,
          0.5288988947868347,
          0.5261918306350708,
          0.5291032195091248,
          0.5291659832000732,
          0.5290595293045044,
          0.52833092212677,
          0.5283437967300415,
          0.5299555063247681
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "scatter": [
           {
            "type": "scatter"
           }
          ]
         }
        },
        "xaxis": {
         "dtick": 1,
         "tick0": 0,
         "title": {
          "text": "Epochs"
         }
        },
        "yaxis": {
         "title": {
          "text": "Accuracy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "epochs = list(range(1,len(fit_log_1_3.history['binary_accuracy'])+1))\n",
    "training_accuracy = fit_log_1_3.history['binary_accuracy']\n",
    "validation_accuracy = fit_log_1_3.history['val_binary_accuracy']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=training_accuracy,\n",
    "    mode='lines',\n",
    "    name='Training'))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=validation_accuracy,\n",
    "    mode='lines',\n",
    "    name='Validation'))\n",
    "fig.update_layout(\n",
    "    template='none',\n",
    "    xaxis_title='Epochs',\n",
    "    yaxis_title=\"Accuracy\")\n",
    "fig.update_xaxes(tick0=0, dtick=1)\n",
    "# fig.update_yaxes(range=[0.5,1])\n",
    "fig.show()\n",
    "fig.write_image(f'../images/model_1_3_accuracy.png', scale=5)\n",
    "pd.DataFrame({'epoch': epochs, 'training_accuracy':training_accuracy, 'validation_accuracy':validation_accuracy}).to_csv('../images/model_1_3_accuracy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://e9df102b-d0e4-4da4-8204-d62605a8d8ac/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://e9df102b-d0e4-4da4-8204-d62605a8d8ac/assets\n",
      "c:\\Users\\nick_\\.virtualenvs\\dotaprediction-eZ2WDOkz\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning:\n",
      "\n",
      "Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://76b5acdc-4d22-4a01-9499-96668dc37710/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://76b5acdc-4d22-4a01-9499-96668dc37710/assets\n",
      "c:\\Users\\nick_\\.virtualenvs\\dotaprediction-eZ2WDOkz\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning:\n",
      "\n",
      "Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filehandler = open(f'../models/fit_log_1_3.pkl','wb')\n",
    "pickle.dump(fit_log_1_3, filehandler)\n",
    "filehandler = open(f'../models/model_1_3.pkl','wb')\n",
    "pickle.dump(model_1_3, filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1.4 - Sum Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nick_\\.virtualenvs\\dotaprediction-eZ2WDOkz\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'DotaV1' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25391/25391 [==============================] - 201s 8ms/step - loss: 0.6952 - binary_accuracy: 0.5122 - val_loss: 0.6946 - val_binary_accuracy: 0.5052\n",
      "Epoch 2/50\n",
      "25391/25391 [==============================] - 176s 7ms/step - loss: 0.6926 - binary_accuracy: 0.5167 - val_loss: 0.6924 - val_binary_accuracy: 0.5153\n",
      "Epoch 3/50\n",
      "25391/25391 [==============================] - 168s 7ms/step - loss: 0.6919 - binary_accuracy: 0.5208 - val_loss: 0.6925 - val_binary_accuracy: 0.5167\n",
      "Epoch 4/50\n",
      "25391/25391 [==============================] - 180s 7ms/step - loss: 0.6915 - binary_accuracy: 0.5232 - val_loss: 0.6922 - val_binary_accuracy: 0.5195\n",
      "Epoch 5/50\n",
      "25391/25391 [==============================] - 231s 9ms/step - loss: 0.6914 - binary_accuracy: 0.5238 - val_loss: 0.6912 - val_binary_accuracy: 0.5254\n",
      "Epoch 6/50\n",
      "25391/25391 [==============================] - 210s 8ms/step - loss: 0.6913 - binary_accuracy: 0.5249 - val_loss: 0.6913 - val_binary_accuracy: 0.5251\n",
      "Epoch 7/50\n",
      "25391/25391 [==============================] - 203s 8ms/step - loss: 0.6912 - binary_accuracy: 0.5252 - val_loss: 0.6910 - val_binary_accuracy: 0.5257\n",
      "Epoch 8/50\n",
      "25391/25391 [==============================] - 204s 8ms/step - loss: 0.6911 - binary_accuracy: 0.5255 - val_loss: 0.6909 - val_binary_accuracy: 0.5269\n",
      "Epoch 9/50\n",
      "25391/25391 [==============================] - 205s 8ms/step - loss: 0.6911 - binary_accuracy: 0.5258 - val_loss: 0.6910 - val_binary_accuracy: 0.5260\n",
      "Epoch 10/50\n",
      "25391/25391 [==============================] - 174s 7ms/step - loss: 0.6911 - binary_accuracy: 0.5262 - val_loss: 0.6911 - val_binary_accuracy: 0.5258\n",
      "Epoch 11/50\n",
      "25391/25391 [==============================] - 158s 6ms/step - loss: 0.6910 - binary_accuracy: 0.5259 - val_loss: 0.6909 - val_binary_accuracy: 0.5270\n",
      "Epoch 12/50\n",
      "25391/25391 [==============================] - 158s 6ms/step - loss: 0.6910 - binary_accuracy: 0.5263 - val_loss: 0.6910 - val_binary_accuracy: 0.5264\n",
      "Epoch 13/50\n",
      "25391/25391 [==============================] - 159s 6ms/step - loss: 0.6910 - binary_accuracy: 0.5268 - val_loss: 0.6917 - val_binary_accuracy: 0.5226\n",
      "Epoch 14/50\n",
      "25391/25391 [==============================] - 158s 6ms/step - loss: 0.6909 - binary_accuracy: 0.5268 - val_loss: 0.6908 - val_binary_accuracy: 0.5276\n",
      "Epoch 15/50\n",
      "25391/25391 [==============================] - 160s 6ms/step - loss: 0.6909 - binary_accuracy: 0.5268 - val_loss: 0.6908 - val_binary_accuracy: 0.5268\n",
      "Epoch 16/50\n",
      "25391/25391 [==============================] - 160s 6ms/step - loss: 0.6909 - binary_accuracy: 0.5269 - val_loss: 0.6908 - val_binary_accuracy: 0.5269\n",
      "Epoch 17/50\n",
      "25391/25391 [==============================] - 156s 6ms/step - loss: 0.6909 - binary_accuracy: 0.5270 - val_loss: 0.6912 - val_binary_accuracy: 0.5273\n",
      "Epoch 18/50\n",
      "25391/25391 [==============================] - 158s 6ms/step - loss: 0.6909 - binary_accuracy: 0.5270 - val_loss: 0.6908 - val_binary_accuracy: 0.5278\n",
      "Epoch 19/50\n",
      "25391/25391 [==============================] - 147s 6ms/step - loss: 0.6909 - binary_accuracy: 0.5271 - val_loss: 0.6908 - val_binary_accuracy: 0.5267\n",
      "Epoch 20/50\n",
      "25391/25391 [==============================] - 144s 6ms/step - loss: 0.6909 - binary_accuracy: 0.5270 - val_loss: 0.6909 - val_binary_accuracy: 0.5271\n",
      "Epoch 21/50\n",
      "25391/25391 [==============================] - 147s 6ms/step - loss: 0.6909 - binary_accuracy: 0.5271 - val_loss: 0.6914 - val_binary_accuracy: 0.5251\n",
      "Epoch 22/50\n",
      "25391/25391 [==============================] - 141s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5271 - val_loss: 0.6906 - val_binary_accuracy: 0.5283\n",
      "Epoch 23/50\n",
      "25391/25391 [==============================] - 141s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5271 - val_loss: 0.6910 - val_binary_accuracy: 0.5259\n",
      "Epoch 24/50\n",
      "25391/25391 [==============================] - 141s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5273 - val_loss: 0.6909 - val_binary_accuracy: 0.5261\n",
      "Epoch 25/50\n",
      "25391/25391 [==============================] - 141s 6ms/step - loss: 0.6909 - binary_accuracy: 0.5273 - val_loss: 0.6908 - val_binary_accuracy: 0.5280\n",
      "Epoch 26/50\n",
      "25391/25391 [==============================] - 151s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5273 - val_loss: 0.6907 - val_binary_accuracy: 0.5276\n",
      "Epoch 27/50\n",
      "25391/25391 [==============================] - 162s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5273 - val_loss: 0.6907 - val_binary_accuracy: 0.5278\n",
      "Epoch 28/50\n",
      "25391/25391 [==============================] - 153s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5272 - val_loss: 0.6907 - val_binary_accuracy: 0.5280\n",
      "Epoch 29/50\n",
      "25391/25391 [==============================] - 167s 7ms/step - loss: 0.6908 - binary_accuracy: 0.5272 - val_loss: 0.6911 - val_binary_accuracy: 0.5256\n",
      "Epoch 30/50\n",
      "25391/25391 [==============================] - 148s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5273 - val_loss: 0.6914 - val_binary_accuracy: 0.5240\n",
      "Epoch 31/50\n",
      "25391/25391 [==============================] - 152s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5274 - val_loss: 0.6911 - val_binary_accuracy: 0.5256\n",
      "Epoch 32/50\n",
      "25391/25391 [==============================] - 174s 7ms/step - loss: 0.6908 - binary_accuracy: 0.5273 - val_loss: 0.6909 - val_binary_accuracy: 0.5262\n",
      "Epoch 33/50\n",
      "25391/25391 [==============================] - 174s 7ms/step - loss: 0.6908 - binary_accuracy: 0.5274 - val_loss: 0.6909 - val_binary_accuracy: 0.5267\n",
      "Epoch 34/50\n",
      "25391/25391 [==============================] - 151s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5275 - val_loss: 0.6909 - val_binary_accuracy: 0.5277\n",
      "Epoch 35/50\n",
      "25391/25391 [==============================] - 151s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5275 - val_loss: 0.6907 - val_binary_accuracy: 0.5277\n",
      "Epoch 36/50\n",
      "25391/25391 [==============================] - 162s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5274 - val_loss: 0.6908 - val_binary_accuracy: 0.5276\n",
      "Epoch 37/50\n",
      "25391/25391 [==============================] - 156s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5275 - val_loss: 0.6907 - val_binary_accuracy: 0.5279\n",
      "Epoch 38/50\n",
      "25391/25391 [==============================] - 148s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5275 - val_loss: 0.6913 - val_binary_accuracy: 0.5266\n",
      "Epoch 39/50\n",
      "25391/25391 [==============================] - 145s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5276 - val_loss: 0.6909 - val_binary_accuracy: 0.5262\n",
      "Epoch 40/50\n",
      "25391/25391 [==============================] - 148s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5275 - val_loss: 0.6909 - val_binary_accuracy: 0.5268\n",
      "Epoch 41/50\n",
      "25391/25391 [==============================] - 150s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5275 - val_loss: 0.6908 - val_binary_accuracy: 0.5273\n",
      "Epoch 42/50\n",
      "25391/25391 [==============================] - 161s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5276 - val_loss: 0.6910 - val_binary_accuracy: 0.5260\n",
      "Epoch 43/50\n",
      "25391/25391 [==============================] - 158s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5275 - val_loss: 0.6907 - val_binary_accuracy: 0.5283\n",
      "Epoch 44/50\n",
      "25391/25391 [==============================] - 153s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5275 - val_loss: 0.6907 - val_binary_accuracy: 0.5281\n",
      "Epoch 45/50\n",
      "25391/25391 [==============================] - 147s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5276 - val_loss: 0.6909 - val_binary_accuracy: 0.5268\n",
      "Epoch 46/50\n",
      "25391/25391 [==============================] - 150s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5277 - val_loss: 0.6906 - val_binary_accuracy: 0.5281\n",
      "Epoch 47/50\n",
      "25391/25391 [==============================] - 145s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5277 - val_loss: 0.6910 - val_binary_accuracy: 0.5271\n",
      "Epoch 48/50\n",
      "25391/25391 [==============================] - 148s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5276 - val_loss: 0.6908 - val_binary_accuracy: 0.5276\n",
      "Epoch 49/50\n",
      "25391/25391 [==============================] - 148s 6ms/step - loss: 0.6908 - binary_accuracy: 0.5274 - val_loss: 0.6907 - val_binary_accuracy: 0.5277\n",
      "Epoch 50/50\n",
      "25391/25391 [==============================] - 126s 5ms/step - loss: 0.6908 - binary_accuracy: 0.5276 - val_loss: 0.6907 - val_binary_accuracy: 0.5273\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "learning_rate = 0.001  # Learning rate\n",
    "epochs = 50  # Number of training epochs\n",
    "es_patience = 10  # Patience for early stopping\n",
    "batch_size = 256  # Batch size\n",
    "\n",
    "# Data loaders\n",
    "loader_tr = BatchLoader(data_tr, batch_size=batch_size, epochs=epochs)\n",
    "loader_va = BatchLoader(data_va, batch_size=batch_size)\n",
    "loader_te = BatchLoader(data_te, batch_size=batch_size)\n",
    "\n",
    "# Build model\n",
    "class Net_1_4(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(19, activation='relu')\n",
    "        self.pool1 = GlobalSumPool()\n",
    "        self.dense = Dense(d.n_labels, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        # x.shape is [n_batches, 5, n_ features]\n",
    "        # a.shape is [n_batches, 5, 5]\n",
    "\n",
    "        x = self.conv1([x, a])\n",
    "        # x.shape is [n_batches, 5, channels] where I have set channels = features (20)\n",
    "\n",
    "        x = self.pool1(x)\n",
    "        # x.shape is [n_batches, channels]\n",
    "\n",
    "        x = self.dense(x)\n",
    "        # output.shape is [n_batches, 1]\n",
    "        \n",
    "        return x\n",
    "\n",
    "model_1_4 = Net_1_4()\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "loss_fn = BinaryCrossentropy()\n",
    "model_1_4.compile(optimizer=optimizer, loss=loss_fn, metrics=['binary_accuracy'])\n",
    "\n",
    "fit_log_1_4 = model_1_4.fit(loader_tr.load(), steps_per_epoch=loader_tr.steps_per_epoch, epochs=epochs, validation_data=loader_va.load(), validation_steps=loader_va.steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "Training",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          0.5122008323669434,
          0.516668975353241,
          0.5207935571670532,
          0.5231715440750122,
          0.5238184928894043,
          0.5248655676841736,
          0.5251603126525879,
          0.5255018472671509,
          0.5257863402366638,
          0.5261926054954529,
          0.5259339809417725,
          0.5263035297393799,
          0.5267620086669922,
          0.5267874002456665,
          0.5268001556396484,
          0.5269113779067993,
          0.5269967913627625,
          0.52699875831604,
          0.5271318554878235,
          0.5270453691482544,
          0.5270665884017944,
          0.5271012187004089,
          0.5271090865135193,
          0.5272773504257202,
          0.5272689461708069,
          0.5273002982139587,
          0.5272579789161682,
          0.5272203087806702,
          0.5272121429443359,
          0.5273405909538269,
          0.5273689031600952,
          0.5273253917694092,
          0.5273786187171936,
          0.5275189280509949,
          0.5274961590766907,
          0.5273696780204773,
          0.5275282859802246,
          0.5275227427482605,
          0.5275864601135254,
          0.5275163054466248,
          0.527458131313324,
          0.527567982673645,
          0.5274993777275085,
          0.527523398399353,
          0.5276055335998535,
          0.5276923179626465,
          0.5276544690132141,
          0.5275933742523193,
          0.5273672342300415,
          0.5276057124137878
         ]
        },
        {
         "mode": "lines",
         "name": "Validation",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          0.5051999688148499,
          0.5152959227561951,
          0.5167377591133118,
          0.5195143222808838,
          0.5254423022270203,
          0.5250829458236694,
          0.525734007358551,
          0.5268545746803284,
          0.5259998440742493,
          0.5257930755615234,
          0.5269813537597656,
          0.5264490842819214,
          0.5225881934165955,
          0.5276035070419312,
          0.5267623066902161,
          0.5268718600273132,
          0.5272706151008606,
          0.527761697769165,
          0.5267266035079956,
          0.5270970463752747,
          0.5250613689422607,
          0.5282939672470093,
          0.5258786082267761,
          0.5261253714561462,
          0.5280225872993469,
          0.5276151895523071,
          0.527839183807373,
          0.5279825925827026,
          0.5255672335624695,
          0.5240121483802795,
          0.5255696773529053,
          0.5261653661727905,
          0.5266613960266113,
          0.527682900428772,
          0.5277056694030762,
          0.527572751045227,
          0.5279309153556824,
          0.5266441702842712,
          0.5262016654014587,
          0.5268207788467407,
          0.5272656679153442,
          0.5259813666343689,
          0.5282995104789734,
          0.5281019806861877,
          0.5268195271492004,
          0.5281093716621399,
          0.5270546078681946,
          0.5275641083717346,
          0.5277401208877563,
          0.5273149013519287
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "scatter": [
           {
            "type": "scatter"
           }
          ]
         }
        },
        "xaxis": {
         "dtick": 1,
         "tick0": 0,
         "title": {
          "text": "Epochs"
         }
        },
        "yaxis": {
         "title": {
          "text": "Accuracy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "epochs = list(range(1,len(fit_log_1_4.history['binary_accuracy'])+1))\n",
    "training_accuracy = fit_log_1_4.history['binary_accuracy']\n",
    "validation_accuracy = fit_log_1_4.history['val_binary_accuracy']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=training_accuracy,\n",
    "    mode='lines',\n",
    "    name='Training'))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=validation_accuracy,\n",
    "    mode='lines',\n",
    "    name='Validation'))\n",
    "fig.update_layout(\n",
    "    template='none',\n",
    "    xaxis_title='Epochs',\n",
    "    yaxis_title=\"Accuracy\")\n",
    "fig.update_xaxes(tick0=0, dtick=1)\n",
    "# fig.update_yaxes(range=[0.5,1])\n",
    "fig.show()\n",
    "fig.write_image(f'../images/model_1_4_accuracy.png', scale=5)\n",
    "pd.DataFrame({'epoch': epochs, 'training_accuracy':training_accuracy, 'validation_accuracy':validation_accuracy}).to_csv('../images/model_1_4_accuracy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://7b05f3e4-e107-475b-a0a1-0b31bdb9debb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nick_\\.virtualenvs\\dotaprediction-eZ2WDOkz\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning:\n",
      "\n",
      "Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://7d89233f-612d-4f45-b1d6-15caf5b93542/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nick_\\.virtualenvs\\dotaprediction-eZ2WDOkz\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning:\n",
      "\n",
      "Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filehandler = open(f'../models/fit_log_1_4.pkl','wb')\n",
    "pickle.dump(fit_log_1_4, filehandler)\n",
    "filehandler = open(f'../models/model_1_4.pkl','wb')\n",
    "pickle.dump(model_1_4, filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1.5 - Attention Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nick_\\.virtualenvs\\dotaprediction-eZ2WDOkz\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning:\n",
      "\n",
      "you are shuffling a 'DotaV1' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25391/25391 [==============================] - 228s 9ms/step - loss: 0.6927 - binary_accuracy: 0.5159 - val_loss: 0.6917 - val_binary_accuracy: 0.5218\n",
      "Epoch 2/50\n",
      "25391/25391 [==============================] - 199s 8ms/step - loss: 0.6916 - binary_accuracy: 0.5219 - val_loss: 0.6913 - val_binary_accuracy: 0.5239\n",
      "Epoch 3/50\n",
      "25391/25391 [==============================] - 199s 8ms/step - loss: 0.6914 - binary_accuracy: 0.5239 - val_loss: 0.6912 - val_binary_accuracy: 0.5252\n",
      "Epoch 4/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6912 - binary_accuracy: 0.5246 - val_loss: 0.6913 - val_binary_accuracy: 0.5243\n",
      "Epoch 5/50\n",
      "25391/25391 [==============================] - 232s 9ms/step - loss: 0.6912 - binary_accuracy: 0.5251 - val_loss: 0.6914 - val_binary_accuracy: 0.5232\n",
      "Epoch 6/50\n",
      "25391/25391 [==============================] - 230s 9ms/step - loss: 0.6911 - binary_accuracy: 0.5254 - val_loss: 0.6914 - val_binary_accuracy: 0.5234\n",
      "Epoch 7/50\n",
      "25391/25391 [==============================] - 214s 8ms/step - loss: 0.6911 - binary_accuracy: 0.5258 - val_loss: 0.6910 - val_binary_accuracy: 0.5260\n",
      "Epoch 8/50\n",
      "25391/25391 [==============================] - 212s 8ms/step - loss: 0.6910 - binary_accuracy: 0.5261 - val_loss: 0.6909 - val_binary_accuracy: 0.5265\n",
      "Epoch 9/50\n",
      "25391/25391 [==============================] - 220s 9ms/step - loss: 0.6910 - binary_accuracy: 0.5260 - val_loss: 0.6910 - val_binary_accuracy: 0.5259\n",
      "Epoch 10/50\n",
      "25391/25391 [==============================] - 220s 9ms/step - loss: 0.6910 - binary_accuracy: 0.5261 - val_loss: 0.6910 - val_binary_accuracy: 0.5268\n",
      "Epoch 11/50\n",
      "25391/25391 [==============================] - 218s 9ms/step - loss: 0.6910 - binary_accuracy: 0.5261 - val_loss: 0.6909 - val_binary_accuracy: 0.5262\n",
      "Epoch 12/50\n",
      "25391/25391 [==============================] - 218s 9ms/step - loss: 0.6909 - binary_accuracy: 0.5263 - val_loss: 0.6909 - val_binary_accuracy: 0.5261\n",
      "Epoch 13/50\n",
      "25391/25391 [==============================] - 203s 8ms/step - loss: 0.6909 - binary_accuracy: 0.5265 - val_loss: 0.6909 - val_binary_accuracy: 0.5267\n",
      "Epoch 14/50\n",
      "25391/25391 [==============================] - 213s 8ms/step - loss: 0.6909 - binary_accuracy: 0.5265 - val_loss: 0.6909 - val_binary_accuracy: 0.5263\n",
      "Epoch 15/50\n",
      "25391/25391 [==============================] - 211s 8ms/step - loss: 0.6909 - binary_accuracy: 0.5266 - val_loss: 0.6912 - val_binary_accuracy: 0.5247\n",
      "Epoch 16/50\n",
      "25391/25391 [==============================] - 211s 8ms/step - loss: 0.6909 - binary_accuracy: 0.5267 - val_loss: 0.6908 - val_binary_accuracy: 0.5270\n",
      "Epoch 17/50\n",
      "25391/25391 [==============================] - 208s 8ms/step - loss: 0.6909 - binary_accuracy: 0.5267 - val_loss: 0.6909 - val_binary_accuracy: 0.5269\n",
      "Epoch 18/50\n",
      "25391/25391 [==============================] - 209s 8ms/step - loss: 0.6909 - binary_accuracy: 0.5269 - val_loss: 0.6912 - val_binary_accuracy: 0.5243\n",
      "Epoch 19/50\n",
      "25391/25391 [==============================] - 208s 8ms/step - loss: 0.6909 - binary_accuracy: 0.5266 - val_loss: 0.6909 - val_binary_accuracy: 0.5267\n",
      "Epoch 20/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6909 - binary_accuracy: 0.5269 - val_loss: 0.6910 - val_binary_accuracy: 0.5263\n",
      "Epoch 21/50\n",
      "25391/25391 [==============================] - 208s 8ms/step - loss: 0.6909 - binary_accuracy: 0.5268 - val_loss: 0.6912 - val_binary_accuracy: 0.5248\n",
      "Epoch 22/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6908 - binary_accuracy: 0.5271 - val_loss: 0.6908 - val_binary_accuracy: 0.5273\n",
      "Epoch 23/50\n",
      "25391/25391 [==============================] - 191s 8ms/step - loss: 0.6908 - binary_accuracy: 0.5271 - val_loss: 0.6909 - val_binary_accuracy: 0.5272\n",
      "Epoch 24/50\n",
      "25391/25391 [==============================] - 192s 8ms/step - loss: 0.6908 - binary_accuracy: 0.5271 - val_loss: 0.6909 - val_binary_accuracy: 0.5267\n",
      "Epoch 25/50\n",
      "25391/25391 [==============================] - 192s 8ms/step - loss: 0.6908 - binary_accuracy: 0.5270 - val_loss: 0.6913 - val_binary_accuracy: 0.5256\n",
      "Epoch 26/50\n",
      "25391/25391 [==============================] - 192s 8ms/step - loss: 0.6908 - binary_accuracy: 0.5269 - val_loss: 0.6908 - val_binary_accuracy: 0.5272\n",
      "Epoch 27/50\n",
      "25391/25391 [==============================] - 193s 8ms/step - loss: 0.6908 - binary_accuracy: 0.5271 - val_loss: 0.6908 - val_binary_accuracy: 0.5270\n",
      "Epoch 28/50\n",
      "25391/25391 [==============================] - 195s 8ms/step - loss: 0.6908 - binary_accuracy: 0.5272 - val_loss: 0.6908 - val_binary_accuracy: 0.5270\n",
      "Epoch 29/50\n",
      "25391/25391 [==============================] - 225s 9ms/step - loss: 0.6908 - binary_accuracy: 0.5272 - val_loss: 0.6908 - val_binary_accuracy: 0.5272\n",
      "Epoch 30/50\n",
      "25391/25391 [==============================] - 196s 8ms/step - loss: 0.6908 - binary_accuracy: 0.5270 - val_loss: 0.6908 - val_binary_accuracy: 0.5269\n",
      "Epoch 31/50\n",
      "25391/25391 [==============================] - 196s 8ms/step - loss: 0.6908 - binary_accuracy: 0.5271 - val_loss: 0.6910 - val_binary_accuracy: 0.5269\n",
      "Epoch 32/50\n",
      "25391/25391 [==============================] - 197s 8ms/step - loss: 0.6908 - binary_accuracy: 0.5272 - val_loss: 0.6908 - val_binary_accuracy: 0.5276\n",
      "Epoch 33/50\n",
      "25391/25391 [==============================] - 200s 8ms/step - loss: 0.6908 - binary_accuracy: 0.5273 - val_loss: 0.6908 - val_binary_accuracy: 0.5270\n",
      "Epoch 34/50\n",
      "25391/25391 [==============================] - 211s 8ms/step - loss: 0.6908 - binary_accuracy: 0.5273 - val_loss: 0.6908 - val_binary_accuracy: 0.5273\n",
      "Epoch 35/50\n",
      "25391/25391 [==============================] - 206s 8ms/step - loss: 0.6908 - binary_accuracy: 0.5274 - val_loss: 0.6908 - val_binary_accuracy: 0.5268\n",
      "Epoch 36/50\n",
      "25391/25391 [==============================] - 219s 9ms/step - loss: 0.6908 - binary_accuracy: 0.5274 - val_loss: 0.6909 - val_binary_accuracy: 0.5265\n",
      "Epoch 37/50\n",
      "25391/25391 [==============================] - 229s 9ms/step - loss: 0.6908 - binary_accuracy: 0.5273 - val_loss: 0.6908 - val_binary_accuracy: 0.5266\n",
      "Epoch 38/50\n",
      "25391/25391 [==============================] - 209s 8ms/step - loss: 0.6908 - binary_accuracy: 0.5273 - val_loss: 0.6907 - val_binary_accuracy: 0.5275\n",
      "Epoch 39/50\n",
      "25391/25391 [==============================] - 216s 9ms/step - loss: 0.6907 - binary_accuracy: 0.5276 - val_loss: 0.6908 - val_binary_accuracy: 0.5267\n",
      "Epoch 40/50\n",
      "25391/25391 [==============================] - 200s 8ms/step - loss: 0.6908 - binary_accuracy: 0.5274 - val_loss: 0.6907 - val_binary_accuracy: 0.5276\n",
      "Epoch 41/50\n",
      "25391/25391 [==============================] - 225s 9ms/step - loss: 0.6907 - binary_accuracy: 0.5275 - val_loss: 0.6908 - val_binary_accuracy: 0.5271\n",
      "Epoch 42/50\n",
      "25391/25391 [==============================] - 201s 8ms/step - loss: 0.6907 - binary_accuracy: 0.5275 - val_loss: 0.6909 - val_binary_accuracy: 0.5264\n",
      "Epoch 43/50\n",
      "25391/25391 [==============================] - 214s 8ms/step - loss: 0.6907 - binary_accuracy: 0.5275 - val_loss: 0.6908 - val_binary_accuracy: 0.5271\n",
      "Epoch 44/50\n",
      "25391/25391 [==============================] - 225s 9ms/step - loss: 0.6908 - binary_accuracy: 0.5275 - val_loss: 0.6908 - val_binary_accuracy: 0.5273\n",
      "Epoch 45/50\n",
      "25391/25391 [==============================] - 224s 9ms/step - loss: 0.6907 - binary_accuracy: 0.5274 - val_loss: 0.6907 - val_binary_accuracy: 0.5276\n",
      "Epoch 46/50\n",
      "25391/25391 [==============================] - 233s 9ms/step - loss: 0.6907 - binary_accuracy: 0.5275 - val_loss: 0.6908 - val_binary_accuracy: 0.5270\n",
      "Epoch 47/50\n",
      "25391/25391 [==============================] - 200s 8ms/step - loss: 0.6907 - binary_accuracy: 0.5274 - val_loss: 0.6909 - val_binary_accuracy: 0.5274\n",
      "Epoch 48/50\n",
      "25391/25391 [==============================] - 195s 8ms/step - loss: 0.6907 - binary_accuracy: 0.5275 - val_loss: 0.6907 - val_binary_accuracy: 0.5274\n",
      "Epoch 49/50\n",
      "25391/25391 [==============================] - 195s 8ms/step - loss: 0.6907 - binary_accuracy: 0.5275 - val_loss: 0.6907 - val_binary_accuracy: 0.5276\n",
      "Epoch 50/50\n",
      "25391/25391 [==============================] - 174s 7ms/step - loss: 0.6907 - binary_accuracy: 0.5275 - val_loss: 0.6909 - val_binary_accuracy: 0.5267\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "learning_rate = 0.001  # Learning rate\n",
    "epochs = 50  # Number of training epochs\n",
    "es_patience = 10  # Patience for early stopping\n",
    "batch_size = 256  # Batch size\n",
    "\n",
    "# Data loaders\n",
    "loader_tr = BatchLoader(data_tr, batch_size=batch_size, epochs=epochs)\n",
    "loader_va = BatchLoader(data_va, batch_size=batch_size)\n",
    "loader_te = BatchLoader(data_te, batch_size=batch_size)\n",
    "\n",
    "# Build model\n",
    "class Net_1_5(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(19, activation='relu')\n",
    "        self.pool1 = GlobalAttentionPool(19)\n",
    "        self.dense = Dense(d.n_labels, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        # x.shape is [n_batches, 5, n_ features]\n",
    "        # a.shape is [n_batches, 5, 5]\n",
    "\n",
    "        x = self.conv1([x, a])\n",
    "        # x.shape is [n_batches, 5, channels] where I have set channels = features (20)\n",
    "\n",
    "        x = self.pool1(x)\n",
    "        # x.shape is [n_batches, channels]\n",
    "\n",
    "        x = self.dense(x)\n",
    "        # output.shape is [n_batches, 1]\n",
    "        \n",
    "        return x\n",
    "\n",
    "model_1_5 = Net_1_5()\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "loss_fn = BinaryCrossentropy()\n",
    "model_1_5.compile(optimizer=optimizer, loss=loss_fn, metrics=['binary_accuracy'])\n",
    "\n",
    "fit_log_1_5 = model_1_5.fit(loader_tr.load(), steps_per_epoch=loader_tr.steps_per_epoch, epochs=epochs, validation_data=loader_va.load(), validation_steps=loader_va.steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "Training",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          0.5159289836883545,
          0.521907389163971,
          0.5239120125770569,
          0.524614155292511,
          0.5251375436782837,
          0.5253649353981018,
          0.5258006453514099,
          0.5260617136955261,
          0.5260382890701294,
          0.5261389017105103,
          0.5261295437812805,
          0.5263190865516663,
          0.5264917016029358,
          0.5264886021614075,
          0.5265652537345886,
          0.5266761779785156,
          0.526721715927124,
          0.5268852114677429,
          0.5266381502151489,
          0.5268558263778687,
          0.5268245935440063,
          0.5270595550537109,
          0.5270538330078125,
          0.527118444442749,
          0.5269799828529358,
          0.5269225835800171,
          0.527111828327179,
          0.5272221565246582,
          0.5271592140197754,
          0.5270037055015564,
          0.5271201729774475,
          0.5272153615951538,
          0.5272744297981262,
          0.5272847414016724,
          0.5273864269256592,
          0.5273987650871277,
          0.5272656679153442,
          0.5273410677909851,
          0.5276283025741577,
          0.5273881554603577,
          0.5274638533592224,
          0.5275056958198547,
          0.5274844765663147,
          0.5274518132209778,
          0.5274062752723694,
          0.5274618268013,
          0.5274400115013123,
          0.5275358557701111,
          0.5274946093559265,
          0.5275192260742188
         ]
        },
        {
         "mode": "lines",
         "name": "Validation",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          0.5218066573143005,
          0.5239161849021912,
          0.5251887440681458,
          0.5243167877197266,
          0.5232478380203247,
          0.523362934589386,
          0.5260306000709534,
          0.5265272259712219,
          0.5258767604827881,
          0.5267844796180725,
          0.5261936783790588,
          0.5261296629905701,
          0.5266810655593872,
          0.5263007879257202,
          0.5247303247451782,
          0.5270103216171265,
          0.5269346237182617,
          0.5242558717727661,
          0.5267444252967834,
          0.5262927412986755,
          0.5247641801834106,
          0.5272669196128845,
          0.5272084474563599,
          0.5267044305801392,
          0.5255709290504456,
          0.5272133946418762,
          0.5270041227340698,
          0.5269604325294495,
          0.527188777923584,
          0.5268933773040771,
          0.5268816947937012,
          0.5275801420211792,
          0.5270447731018066,
          0.5273346304893494,
          0.5268465876579285,
          0.5265241265296936,
          0.5266035199165344,
          0.527534008026123,
          0.5267136693000793,
          0.5275579690933228,
          0.5270656943321228,
          0.5264269113540649,
          0.5271333456039429,
          0.527341365814209,
          0.5276386141777039,
          0.5269548892974854,
          0.527354896068573,
          0.52742999792099,
          0.5275893807411194,
          0.5266632437705994
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "scatter": [
           {
            "type": "scatter"
           }
          ]
         }
        },
        "xaxis": {
         "dtick": 1,
         "tick0": 0,
         "title": {
          "text": "Epochs"
         }
        },
        "yaxis": {
         "title": {
          "text": "Accuracy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "epochs = list(range(1,len(fit_log_1_5.history['binary_accuracy'])+1))\n",
    "training_accuracy = fit_log_1_5.history['binary_accuracy']\n",
    "validation_accuracy = fit_log_1_5.history['val_binary_accuracy']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=training_accuracy,\n",
    "    mode='lines',\n",
    "    name='Training'))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=validation_accuracy,\n",
    "    mode='lines',\n",
    "    name='Validation'))\n",
    "fig.update_layout(\n",
    "    template='none',\n",
    "    xaxis_title='Epochs',\n",
    "    yaxis_title=\"Accuracy\")\n",
    "fig.update_xaxes(tick0=0, dtick=1)\n",
    "# fig.update_yaxes(range=[0.5,1])\n",
    "fig.show()\n",
    "fig.write_image(f'../images/model_1_5_accuracy.png', scale=5)\n",
    "pd.DataFrame({'epoch': epochs, 'training_accuracy':training_accuracy, 'validation_accuracy':validation_accuracy}).to_csv('../images/model_1_5_accuracy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as features_layer_layer_call_fn, features_layer_layer_call_and_return_conditional_losses, attn_layer_layer_call_fn, attn_layer_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://ee72e0e3-707c-4145-8268-8824588a1440/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://ee72e0e3-707c-4145-8268-8824588a1440/assets\n",
      "WARNING:absl:Found untraced functions such as features_layer_layer_call_fn, features_layer_layer_call_and_return_conditional_losses, attn_layer_layer_call_fn, attn_layer_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://ad7d20c4-5181-4e3a-abca-786392bddfb6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://ad7d20c4-5181-4e3a-abca-786392bddfb6/assets\n"
     ]
    }
   ],
   "source": [
    "filehandler = open(f'../models/fit_log_1_5.pkl','wb')\n",
    "pickle.dump(fit_log_1_5, filehandler)\n",
    "filehandler = open(f'../models/model_1_5.pkl','wb')\n",
    "pickle.dump(model_1_5, filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1.6 GATConv + Average Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nick_\\.virtualenvs\\dotaprediction-eZ2WDOkz\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning:\n",
      "\n",
      "you are shuffling a 'DotaV1' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25391/25391 [==============================] - 427s 17ms/step - loss: 0.6913 - binary_accuracy: 0.5262 - val_loss: 0.6908 - val_binary_accuracy: 0.5283\n",
      "Epoch 2/50\n",
      "25391/25391 [==============================] - 296s 12ms/step - loss: 0.6903 - binary_accuracy: 0.5324 - val_loss: 0.6901 - val_binary_accuracy: 0.5324\n",
      "Epoch 3/50\n",
      "25391/25391 [==============================] - 287s 11ms/step - loss: 0.6900 - binary_accuracy: 0.5336 - val_loss: 0.6901 - val_binary_accuracy: 0.5325\n",
      "Epoch 4/50\n",
      "25391/25391 [==============================] - 279s 11ms/step - loss: 0.6899 - binary_accuracy: 0.5337 - val_loss: 0.6899 - val_binary_accuracy: 0.5341\n",
      "Epoch 5/50\n",
      "25391/25391 [==============================] - 281s 11ms/step - loss: 0.6898 - binary_accuracy: 0.5342 - val_loss: 0.6900 - val_binary_accuracy: 0.5331\n",
      "Epoch 6/50\n",
      "25391/25391 [==============================] - 286s 11ms/step - loss: 0.6897 - binary_accuracy: 0.5348 - val_loss: 0.6903 - val_binary_accuracy: 0.5315\n",
      "Epoch 7/50\n",
      "25391/25391 [==============================] - 265s 10ms/step - loss: 0.6897 - binary_accuracy: 0.5347 - val_loss: 0.6899 - val_binary_accuracy: 0.5333\n",
      "Epoch 8/50\n",
      "25391/25391 [==============================] - 265s 10ms/step - loss: 0.6897 - binary_accuracy: 0.5348 - val_loss: 0.6897 - val_binary_accuracy: 0.5344\n",
      "Epoch 9/50\n",
      "25391/25391 [==============================] - 241s 10ms/step - loss: 0.6896 - binary_accuracy: 0.5351 - val_loss: 0.6899 - val_binary_accuracy: 0.5323\n",
      "Epoch 10/50\n",
      "25391/25391 [==============================] - 258s 10ms/step - loss: 0.6896 - binary_accuracy: 0.5351 - val_loss: 0.6895 - val_binary_accuracy: 0.5351\n",
      "Epoch 11/50\n",
      "25391/25391 [==============================] - 256s 10ms/step - loss: 0.6895 - binary_accuracy: 0.5354 - val_loss: 0.6898 - val_binary_accuracy: 0.5336\n",
      "Epoch 12/50\n",
      "25391/25391 [==============================] - 252s 10ms/step - loss: 0.6895 - binary_accuracy: 0.5356 - val_loss: 0.6898 - val_binary_accuracy: 0.5342\n",
      "Epoch 13/50\n",
      "25391/25391 [==============================] - 267s 11ms/step - loss: 0.6895 - binary_accuracy: 0.5355 - val_loss: 0.6895 - val_binary_accuracy: 0.5348\n",
      "Epoch 14/50\n",
      "25391/25391 [==============================] - 273s 11ms/step - loss: 0.6895 - binary_accuracy: 0.5359 - val_loss: 0.6896 - val_binary_accuracy: 0.5342\n",
      "Epoch 15/50\n",
      "25391/25391 [==============================] - 265s 10ms/step - loss: 0.6895 - binary_accuracy: 0.5357 - val_loss: 0.6897 - val_binary_accuracy: 0.5344\n",
      "Epoch 16/50\n",
      "25391/25391 [==============================] - 275s 11ms/step - loss: 0.6894 - binary_accuracy: 0.5359 - val_loss: 0.6895 - val_binary_accuracy: 0.5348\n",
      "Epoch 17/50\n",
      "25391/25391 [==============================] - 268s 11ms/step - loss: 0.6894 - binary_accuracy: 0.5360 - val_loss: 0.6894 - val_binary_accuracy: 0.5352\n",
      "Epoch 18/50\n",
      "25391/25391 [==============================] - 247s 10ms/step - loss: 0.6894 - binary_accuracy: 0.5360 - val_loss: 0.6897 - val_binary_accuracy: 0.5339\n",
      "Epoch 19/50\n",
      "25391/25391 [==============================] - 254s 10ms/step - loss: 0.6894 - binary_accuracy: 0.5360 - val_loss: 0.6895 - val_binary_accuracy: 0.5348\n",
      "Epoch 20/50\n",
      "25391/25391 [==============================] - 257s 10ms/step - loss: 0.6894 - binary_accuracy: 0.5357 - val_loss: 0.6896 - val_binary_accuracy: 0.5345\n",
      "Epoch 21/50\n",
      "25391/25391 [==============================] - 264s 10ms/step - loss: 0.6894 - binary_accuracy: 0.5360 - val_loss: 0.6894 - val_binary_accuracy: 0.5356\n",
      "Epoch 22/50\n",
      "25391/25391 [==============================] - 261s 10ms/step - loss: 0.6893 - binary_accuracy: 0.5360 - val_loss: 0.6896 - val_binary_accuracy: 0.5344\n",
      "Epoch 23/50\n",
      "25391/25391 [==============================] - 263s 10ms/step - loss: 0.6893 - binary_accuracy: 0.5363 - val_loss: 0.6898 - val_binary_accuracy: 0.5338\n",
      "Epoch 24/50\n",
      "25391/25391 [==============================] - 259s 10ms/step - loss: 0.6894 - binary_accuracy: 0.5360 - val_loss: 0.6897 - val_binary_accuracy: 0.5334\n",
      "Epoch 25/50\n",
      "25391/25391 [==============================] - 256s 10ms/step - loss: 0.6893 - binary_accuracy: 0.5362 - val_loss: 0.6896 - val_binary_accuracy: 0.5348\n",
      "Epoch 26/50\n",
      "25391/25391 [==============================] - 262s 10ms/step - loss: 0.6893 - binary_accuracy: 0.5364 - val_loss: 0.6893 - val_binary_accuracy: 0.5356\n",
      "Epoch 27/50\n",
      "25391/25391 [==============================] - 260s 10ms/step - loss: 0.6893 - binary_accuracy: 0.5362 - val_loss: 0.6897 - val_binary_accuracy: 0.5337\n",
      "Epoch 28/50\n",
      "25391/25391 [==============================] - 240s 9ms/step - loss: 0.6893 - binary_accuracy: 0.5362 - val_loss: 0.6896 - val_binary_accuracy: 0.5348\n",
      "Epoch 29/50\n",
      "25391/25391 [==============================] - 240s 9ms/step - loss: 0.6893 - binary_accuracy: 0.5362 - val_loss: 0.6899 - val_binary_accuracy: 0.5328\n",
      "Epoch 30/50\n",
      "25391/25391 [==============================] - 263s 10ms/step - loss: 0.6893 - binary_accuracy: 0.5365 - val_loss: 0.6896 - val_binary_accuracy: 0.5341\n",
      "Epoch 31/50\n",
      "25391/25391 [==============================] - 262s 10ms/step - loss: 0.6893 - binary_accuracy: 0.5363 - val_loss: 0.6895 - val_binary_accuracy: 0.5346\n",
      "Epoch 32/50\n",
      "25391/25391 [==============================] - 262s 10ms/step - loss: 0.6893 - binary_accuracy: 0.5364 - val_loss: 0.6897 - val_binary_accuracy: 0.5340\n",
      "Epoch 33/50\n",
      "25391/25391 [==============================] - 256s 10ms/step - loss: 0.6893 - binary_accuracy: 0.5363 - val_loss: 0.6895 - val_binary_accuracy: 0.5344\n",
      "Epoch 34/50\n",
      "25391/25391 [==============================] - 241s 9ms/step - loss: 0.6893 - binary_accuracy: 0.5364 - val_loss: 0.6897 - val_binary_accuracy: 0.5342\n",
      "Epoch 35/50\n",
      "25391/25391 [==============================] - 242s 10ms/step - loss: 0.6893 - binary_accuracy: 0.5364 - val_loss: 0.6894 - val_binary_accuracy: 0.5354\n",
      "Epoch 36/50\n",
      "25391/25391 [==============================] - 241s 9ms/step - loss: 0.6893 - binary_accuracy: 0.5365 - val_loss: 0.6897 - val_binary_accuracy: 0.5337\n",
      "Epoch 37/50\n",
      "25391/25391 [==============================] - 240s 9ms/step - loss: 0.6893 - binary_accuracy: 0.5363 - val_loss: 0.6895 - val_binary_accuracy: 0.5347\n",
      "Epoch 38/50\n",
      "25391/25391 [==============================] - 256s 10ms/step - loss: 0.6893 - binary_accuracy: 0.5363 - val_loss: 0.6896 - val_binary_accuracy: 0.5339\n",
      "Epoch 39/50\n",
      "25391/25391 [==============================] - 263s 10ms/step - loss: 0.6893 - binary_accuracy: 0.5364 - val_loss: 0.6897 - val_binary_accuracy: 0.5336\n",
      "Epoch 40/50\n",
      "25391/25391 [==============================] - 259s 10ms/step - loss: 0.6892 - binary_accuracy: 0.5366 - val_loss: 0.6895 - val_binary_accuracy: 0.5343\n",
      "Epoch 41/50\n",
      "25391/25391 [==============================] - 261s 10ms/step - loss: 0.6892 - binary_accuracy: 0.5367 - val_loss: 0.6893 - val_binary_accuracy: 0.5355\n",
      "Epoch 42/50\n",
      "25391/25391 [==============================] - 264s 10ms/step - loss: 0.6893 - binary_accuracy: 0.5364 - val_loss: 0.6895 - val_binary_accuracy: 0.5352\n",
      "Epoch 43/50\n",
      "25391/25391 [==============================] - 262s 10ms/step - loss: 0.6893 - binary_accuracy: 0.5362 - val_loss: 0.6893 - val_binary_accuracy: 0.5357\n",
      "Epoch 44/50\n",
      "25391/25391 [==============================] - 261s 10ms/step - loss: 0.6893 - binary_accuracy: 0.5364 - val_loss: 0.6896 - val_binary_accuracy: 0.5341\n",
      "Epoch 45/50\n",
      "25391/25391 [==============================] - 251s 10ms/step - loss: 0.6892 - binary_accuracy: 0.5365 - val_loss: 0.6896 - val_binary_accuracy: 0.5347\n",
      "Epoch 46/50\n",
      "25391/25391 [==============================] - 241s 9ms/step - loss: 0.6892 - binary_accuracy: 0.5366 - val_loss: 0.6895 - val_binary_accuracy: 0.5347\n",
      "Epoch 47/50\n",
      "25391/25391 [==============================] - 240s 9ms/step - loss: 0.6892 - binary_accuracy: 0.5365 - val_loss: 0.6899 - val_binary_accuracy: 0.5331\n",
      "Epoch 48/50\n",
      "25391/25391 [==============================] - 240s 9ms/step - loss: 0.6892 - binary_accuracy: 0.5365 - val_loss: 0.6894 - val_binary_accuracy: 0.5350\n",
      "Epoch 49/50\n",
      "25391/25391 [==============================] - 272s 11ms/step - loss: 0.6892 - binary_accuracy: 0.5365 - val_loss: 0.6895 - val_binary_accuracy: 0.5348\n",
      "Epoch 50/50\n",
      "25391/25391 [==============================] - 248s 10ms/step - loss: 0.6892 - binary_accuracy: 0.5365 - val_loss: 0.6895 - val_binary_accuracy: 0.5347\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "learning_rate = 0.001  # Learning rate\n",
    "epochs = 50  # Number of training epochs\n",
    "es_patience = 10  # Patience for early stopping\n",
    "batch_size = 256  # Batch size\n",
    "\n",
    "# Data loaders\n",
    "loader_tr = BatchLoader(data_tr, batch_size=batch_size, epochs=epochs)\n",
    "loader_va = BatchLoader(data_va, batch_size=batch_size)\n",
    "loader_te = BatchLoader(data_te, batch_size=batch_size)\n",
    "\n",
    "# Build model\n",
    "class Net_1_6(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(19, activation='relu')\n",
    "        self.pool1 = GlobalAvgPool()\n",
    "        self.dense = Dense(d.n_labels, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        # x.shape is [n_batches, 5, n_ features]\n",
    "        # a.shape is [n_batches, 5, 5]\n",
    "\n",
    "        x = self.conv1([x, a])\n",
    "        # x.shape is [n_batches, 5, channels] where I have set channels = features (20)\n",
    "\n",
    "        x = self.pool1(x)\n",
    "        # x.shape is [n_batches, channels]\n",
    "\n",
    "        x = self.dense(x)\n",
    "        # output.shape is [n_batches, 1]\n",
    "        \n",
    "        return x\n",
    "\n",
    "model_1_6 = Net_1_6()\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "loss_fn = BinaryCrossentropy()\n",
    "model_1_6.compile(optimizer=optimizer, loss=loss_fn, metrics=['binary_accuracy'])\n",
    "\n",
    "fit_log_1_6 = model_1_6.fit(loader_tr.load(), steps_per_epoch=loader_tr.steps_per_epoch, epochs=epochs, validation_data=loader_va.load(), validation_steps=loader_va.steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "Training",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          0.5261957049369812,
          0.5324413776397705,
          0.533639669418335,
          0.5337373614311218,
          0.5342265963554382,
          0.5348391532897949,
          0.5347336530685425,
          0.534839928150177,
          0.5351108908653259,
          0.5350888967514038,
          0.5354159474372864,
          0.5355927348136902,
          0.5355191826820374,
          0.5358594655990601,
          0.5356647372245789,
          0.5358942747116089,
          0.5359894633293152,
          0.5360274910926819,
          0.5360188484191895,
          0.5357142686843872,
          0.5360389947891235,
          0.5360325574874878,
          0.5363259315490723,
          0.5360158085823059,
          0.5361859202384949,
          0.5363731980323792,
          0.536238431930542,
          0.5362110137939453,
          0.5362036228179932,
          0.5365336537361145,
          0.5363282561302185,
          0.5364476442337036,
          0.5363316535949707,
          0.5363785624504089,
          0.5364487171173096,
          0.5364781022071838,
          0.5362520813941956,
          0.5363070368766785,
          0.5364136099815369,
          0.5366027355194092,
          0.5366674661636353,
          0.5364363789558411,
          0.5362483859062195,
          0.5364421010017395,
          0.5364856123924255,
          0.5366261005401611,
          0.5364914536476135,
          0.5365374684333801,
          0.5365284085273743,
          0.5365230441093445
         ]
        },
        {
         "mode": "lines",
         "name": "Validation",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          0.5283420085906982,
          0.5324262380599976,
          0.5324878096580505,
          0.5340631604194641,
          0.533146858215332,
          0.5314558148384094,
          0.5333443880081177,
          0.5343942642211914,
          0.5323253273963928,
          0.5350508689880371,
          0.5335899591445923,
          0.5341671705245972,
          0.5348453521728516,
          0.5341776609420776,
          0.5343616604804993,
          0.5347696542739868,
          0.5352489948272705,
          0.5339290499687195,
          0.5348065495491028,
          0.5345118045806885,
          0.5356317758560181,
          0.5344163775444031,
          0.5337899327278137,
          0.5334213376045227,
          0.5348028540611267,
          0.5355806946754456,
          0.5336970090866089,
          0.5347591638565063,
          0.5327967405319214,
          0.5341364145278931,
          0.5346053242683411,
          0.5339973568916321,
          0.5344170331954956,
          0.5341991782188416,
          0.5353788733482361,
          0.5336699485778809,
          0.5347400903701782,
          0.5339241027832031,
          0.5336312055587769,
          0.5343025326728821,
          0.5354631543159485,
          0.5352416038513184,
          0.535741925239563,
          0.5341025590896606,
          0.5347363948822021,
          0.5346601009368896,
          0.5330502390861511,
          0.5350410342216492,
          0.5347794890403748,
          0.5346791744232178
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "scatter": [
           {
            "type": "scatter"
           }
          ]
         }
        },
        "xaxis": {
         "dtick": 1,
         "tick0": 0,
         "title": {
          "text": "Epochs"
         }
        },
        "yaxis": {
         "title": {
          "text": "Accuracy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "epochs = list(range(1,len(fit_log_1_6.history['binary_accuracy'])+1))\n",
    "training_accuracy = fit_log_1_6.history['binary_accuracy']\n",
    "validation_accuracy = fit_log_1_6.history['val_binary_accuracy']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=training_accuracy,\n",
    "    mode='lines',\n",
    "    name='Training'))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=validation_accuracy,\n",
    "    mode='lines',\n",
    "    name='Validation'))\n",
    "fig.update_layout(\n",
    "    template='none',\n",
    "    xaxis_title='Epochs',\n",
    "    yaxis_title=\"Accuracy\")\n",
    "fig.update_xaxes(tick0=0, dtick=1)\n",
    "# fig.update_yaxes(range=[0.5,1])\n",
    "fig.show()\n",
    "fig.write_image(f'../images/model_1_6_accuracy.png', scale=5)\n",
    "pd.DataFrame({'epoch': epochs, 'training_accuracy':training_accuracy, 'validation_accuracy':validation_accuracy}).to_csv('../images/model_1_6_accuracy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dropout_layer_call_fn, dropout_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://8742329e-711a-454c-b91d-20d06fba93f4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://8742329e-711a-454c-b91d-20d06fba93f4/assets\n",
      "c:\\Users\\nick_\\.virtualenvs\\dotaprediction-eZ2WDOkz\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning:\n",
      "\n",
      "Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "\n",
      "WARNING:absl:Found untraced functions such as dropout_layer_call_fn, dropout_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://abbef555-889d-4fe7-9229-fe444bf287db/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://abbef555-889d-4fe7-9229-fe444bf287db/assets\n",
      "c:\\Users\\nick_\\.virtualenvs\\dotaprediction-eZ2WDOkz\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning:\n",
      "\n",
      "Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filehandler = open(f'../models/fit_log_1_6.pkl','wb')\n",
    "pickle.dump(fit_log_1_6, filehandler)\n",
    "filehandler = open(f'../models/model_1_6.pkl','wb')\n",
    "pickle.dump(model_1_6, filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1.7 - Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting specific columns:\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3100000\n",
      "3200000\n",
      "3300000\n",
      "3400000\n",
      "3500000\n",
      "3600000\n",
      "3700000\n",
      "3800000\n",
      "3900000\n",
      "4000000\n",
      "4100000\n",
      "4200000\n",
      "4300000\n",
      "4400000\n",
      "4500000\n",
      "4600000\n",
      "4700000\n",
      "4800000\n",
      "4900000\n",
      "5000000\n",
      "5100000\n",
      "5200000\n",
      "5300000\n",
      "5400000\n",
      "5500000\n",
      "5600000\n",
      "5700000\n",
      "5800000\n",
      "5900000\n",
      "6000000\n",
      "6100000\n",
      "6200000\n",
      "6300000\n",
      "6400000\n",
      "6500000\n",
      "6600000\n",
      "6700000\n",
      "6800000\n",
      "6900000\n",
      "7000000\n",
      "7100000\n",
      "7200000\n",
      "7300000\n",
      "7400000\n",
      "7500000\n",
      "7600000\n",
      "7700000\n",
      "7800000\n",
      "7900000\n",
      "8000000\n",
      "8100000\n",
      "8200000\n",
      "8300000\n",
      "8400000\n",
      "8500000\n",
      "8600000\n",
      "8700000\n",
      "8800000\n",
      "8900000\n",
      "9000000\n",
      "9100000\n",
      "9200000\n",
      "9300000\n",
      "9400000\n",
      "9500000\n",
      "9600000\n",
      "9700000\n",
      "9800000\n",
      "9900000\n",
      "10000000\n",
      "10100000\n"
     ]
    }
   ],
   "source": [
    "# Loop through each graph and scale feature matrix and drop following features: (col numbers are after removing attack_backswing (14) earlier)\n",
    "\n",
    "# base_attack_time (12)\n",
    "# attack_point (13)\n",
    "# vision_day (14)\n",
    "# vision_night (15)\n",
    "# turn_rate (16)\n",
    "# collision_size (17)\n",
    "\n",
    "print('Selecting specific columns:')\n",
    "for i in range(0,len(graphs_filt)): # match 0 has only 15 features, reason not known, skipping this\n",
    "    if(i%100000==0):\n",
    "        print(i)\n",
    "\n",
    "    graphs_filt[i].x = graphs_filt[i].x[:,[0,1,2,3,4,5,6,7,8,9,10,11,18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 64.0%\n",
      "Validation data: 16.0%\n",
      "Test data: 20.0%\n"
     ]
    }
   ],
   "source": [
    "# Train/valid/test split\n",
    "d_fs = graphs_filt # Graph data\n",
    "\n",
    "# np.random.seed(10)\n",
    "idxs = np.random.permutation(len(d_fs))\n",
    "split_va, split_te = int(0.64 * len(d_fs)), int(0.8 * len(d_fs)) #64% training, 16% validation, 20% test\n",
    "# idx_tr, idx_va, idx_te = np.split(idxs, [split_va, split_te]) # use indices from earlier split\n",
    "data_tr_fs = d_fs[idx_tr]\n",
    "data_va_fs = d_fs[idx_va]\n",
    "data_te_fs = d_fs[idx_te]\n",
    "\n",
    "print(f'Training data: {np.round(len(data_tr_fs)/len(graphs_filt),2)*100}%')\n",
    "print(f'Validation data: {np.round(len(data_va_fs)/len(graphs_filt),2)*100}%')\n",
    "print(f'Test data: {np.round(len(data_te_fs)/len(graphs_filt),2)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nick_\\miniconda3\\envs\\tf\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'DotaV1' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25391/25391 [==============================] - 216s 8ms/step - loss: 0.6919 - binary_accuracy: 0.5202 - val_loss: 0.6920 - val_binary_accuracy: 0.5187\n",
      "Epoch 2/50\n",
      "25391/25391 [==============================] - 200s 8ms/step - loss: 0.6914 - binary_accuracy: 0.5255 - val_loss: 0.6919 - val_binary_accuracy: 0.5205\n",
      "Epoch 3/50\n",
      "25391/25391 [==============================] - 199s 8ms/step - loss: 0.6912 - binary_accuracy: 0.5264 - val_loss: 0.6919 - val_binary_accuracy: 0.5202\n",
      "Epoch 4/50\n",
      "25391/25391 [==============================] - 201s 8ms/step - loss: 0.6911 - binary_accuracy: 0.5275 - val_loss: 0.6917 - val_binary_accuracy: 0.5212\n",
      "Epoch 5/50\n",
      "25391/25391 [==============================] - 199s 8ms/step - loss: 0.6910 - binary_accuracy: 0.5280 - val_loss: 0.6916 - val_binary_accuracy: 0.5226\n",
      "Epoch 6/50\n",
      "25391/25391 [==============================] - 185s 7ms/step - loss: 0.6909 - binary_accuracy: 0.5286 - val_loss: 0.6917 - val_binary_accuracy: 0.5217\n",
      "Epoch 7/50\n",
      "25391/25391 [==============================] - 184s 7ms/step - loss: 0.6908 - binary_accuracy: 0.5289 - val_loss: 0.6916 - val_binary_accuracy: 0.5227\n",
      "Epoch 8/50\n",
      "25391/25391 [==============================] - 199s 8ms/step - loss: 0.6907 - binary_accuracy: 0.5295 - val_loss: 0.6919 - val_binary_accuracy: 0.5219\n",
      "Epoch 9/50\n",
      "25391/25391 [==============================] - 201s 8ms/step - loss: 0.6907 - binary_accuracy: 0.5299 - val_loss: 0.6914 - val_binary_accuracy: 0.5240\n",
      "Epoch 10/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6906 - binary_accuracy: 0.5300 - val_loss: 0.6915 - val_binary_accuracy: 0.5237\n",
      "Epoch 11/50\n",
      "25391/25391 [==============================] - 188s 7ms/step - loss: 0.6906 - binary_accuracy: 0.5303 - val_loss: 0.6918 - val_binary_accuracy: 0.5212\n",
      "Epoch 12/50\n",
      "25391/25391 [==============================] - 194s 8ms/step - loss: 0.6905 - binary_accuracy: 0.5305 - val_loss: 0.6916 - val_binary_accuracy: 0.5224\n",
      "Epoch 13/50\n",
      "25391/25391 [==============================] - 182s 7ms/step - loss: 0.6905 - binary_accuracy: 0.5306 - val_loss: 0.6915 - val_binary_accuracy: 0.5231\n",
      "Epoch 14/50\n",
      "25391/25391 [==============================] - 186s 7ms/step - loss: 0.6906 - binary_accuracy: 0.5305 - val_loss: 0.6919 - val_binary_accuracy: 0.5205\n",
      "Epoch 15/50\n",
      "25391/25391 [==============================] - 200s 8ms/step - loss: 0.6905 - binary_accuracy: 0.5309 - val_loss: 0.6916 - val_binary_accuracy: 0.5231\n",
      "Epoch 16/50\n",
      "25391/25391 [==============================] - 205s 8ms/step - loss: 0.6905 - binary_accuracy: 0.5309 - val_loss: 0.6915 - val_binary_accuracy: 0.5235\n",
      "Epoch 17/50\n",
      "25391/25391 [==============================] - 197s 8ms/step - loss: 0.6905 - binary_accuracy: 0.5307 - val_loss: 0.6914 - val_binary_accuracy: 0.5244\n",
      "Epoch 18/50\n",
      "25391/25391 [==============================] - 199s 8ms/step - loss: 0.6905 - binary_accuracy: 0.5309 - val_loss: 0.6915 - val_binary_accuracy: 0.5241\n",
      "Epoch 19/50\n",
      "25391/25391 [==============================] - 205s 8ms/step - loss: 0.6905 - binary_accuracy: 0.5308 - val_loss: 0.6916 - val_binary_accuracy: 0.5228\n",
      "Epoch 20/50\n",
      "25391/25391 [==============================] - 205s 8ms/step - loss: 0.6904 - binary_accuracy: 0.5311 - val_loss: 0.6918 - val_binary_accuracy: 0.5204\n",
      "Epoch 21/50\n",
      "25391/25391 [==============================] - 206s 8ms/step - loss: 0.6905 - binary_accuracy: 0.5311 - val_loss: 0.6914 - val_binary_accuracy: 0.5241\n",
      "Epoch 22/50\n",
      "25391/25391 [==============================] - 205s 8ms/step - loss: 0.6905 - binary_accuracy: 0.5310 - val_loss: 0.6914 - val_binary_accuracy: 0.5248\n",
      "Epoch 23/50\n",
      "25391/25391 [==============================] - 209s 8ms/step - loss: 0.6904 - binary_accuracy: 0.5313 - val_loss: 0.6916 - val_binary_accuracy: 0.5230\n",
      "Epoch 24/50\n",
      "25391/25391 [==============================] - 209s 8ms/step - loss: 0.6904 - binary_accuracy: 0.5313 - val_loss: 0.6916 - val_binary_accuracy: 0.5223\n",
      "Epoch 25/50\n",
      "25391/25391 [==============================] - 205s 8ms/step - loss: 0.6904 - binary_accuracy: 0.5316 - val_loss: 0.6914 - val_binary_accuracy: 0.5243\n",
      "Epoch 26/50\n",
      "25391/25391 [==============================] - 210s 8ms/step - loss: 0.6904 - binary_accuracy: 0.5312 - val_loss: 0.6916 - val_binary_accuracy: 0.5228\n",
      "Epoch 27/50\n",
      "25391/25391 [==============================] - 208s 8ms/step - loss: 0.6904 - binary_accuracy: 0.5312 - val_loss: 0.6919 - val_binary_accuracy: 0.5212\n",
      "Epoch 28/50\n",
      "25391/25391 [==============================] - 208s 8ms/step - loss: 0.6904 - binary_accuracy: 0.5315 - val_loss: 0.6915 - val_binary_accuracy: 0.5238\n",
      "Epoch 29/50\n",
      "25391/25391 [==============================] - 205s 8ms/step - loss: 0.6904 - binary_accuracy: 0.5314 - val_loss: 0.6917 - val_binary_accuracy: 0.5217\n",
      "Epoch 30/50\n",
      "25391/25391 [==============================] - 207s 8ms/step - loss: 0.6904 - binary_accuracy: 0.5313 - val_loss: 0.6913 - val_binary_accuracy: 0.5246\n",
      "Epoch 31/50\n",
      "25391/25391 [==============================] - 232s 9ms/step - loss: 0.6904 - binary_accuracy: 0.5315 - val_loss: 0.6919 - val_binary_accuracy: 0.5208\n",
      "Epoch 32/50\n",
      "25391/25391 [==============================] - 223s 9ms/step - loss: 0.6904 - binary_accuracy: 0.5317 - val_loss: 0.6920 - val_binary_accuracy: 0.5190\n",
      "Epoch 33/50\n",
      "25391/25391 [==============================] - 214s 8ms/step - loss: 0.6904 - binary_accuracy: 0.5315 - val_loss: 0.6915 - val_binary_accuracy: 0.5230\n",
      "Epoch 34/50\n",
      "25391/25391 [==============================] - 214s 8ms/step - loss: 0.6903 - binary_accuracy: 0.5316 - val_loss: 0.6915 - val_binary_accuracy: 0.5239\n",
      "Epoch 35/50\n",
      "25391/25391 [==============================] - 216s 8ms/step - loss: 0.6903 - binary_accuracy: 0.5316 - val_loss: 0.6916 - val_binary_accuracy: 0.5220\n",
      "Epoch 36/50\n",
      "25391/25391 [==============================] - 212s 8ms/step - loss: 0.6904 - binary_accuracy: 0.5316 - val_loss: 0.6918 - val_binary_accuracy: 0.5216\n",
      "Epoch 37/50\n",
      "25391/25391 [==============================] - 212s 8ms/step - loss: 0.6903 - binary_accuracy: 0.5319 - val_loss: 0.6915 - val_binary_accuracy: 0.5238\n",
      "Epoch 38/50\n",
      "25391/25391 [==============================] - 210s 8ms/step - loss: 0.6903 - binary_accuracy: 0.5319 - val_loss: 0.6918 - val_binary_accuracy: 0.5211\n",
      "Epoch 39/50\n",
      "25391/25391 [==============================] - 201s 8ms/step - loss: 0.6903 - binary_accuracy: 0.5317 - val_loss: 0.6918 - val_binary_accuracy: 0.5213\n",
      "Epoch 40/50\n",
      "25391/25391 [==============================] - 206s 8ms/step - loss: 0.6903 - binary_accuracy: 0.5320 - val_loss: 0.6918 - val_binary_accuracy: 0.5205\n",
      "Epoch 41/50\n",
      "25391/25391 [==============================] - 202s 8ms/step - loss: 0.6903 - binary_accuracy: 0.5320 - val_loss: 0.6916 - val_binary_accuracy: 0.5233\n",
      "Epoch 42/50\n",
      "25391/25391 [==============================] - 215s 8ms/step - loss: 0.6903 - binary_accuracy: 0.5316 - val_loss: 0.6914 - val_binary_accuracy: 0.5246\n",
      "Epoch 43/50\n",
      "25391/25391 [==============================] - 210s 8ms/step - loss: 0.6903 - binary_accuracy: 0.5320 - val_loss: 0.6920 - val_binary_accuracy: 0.5195\n",
      "Epoch 44/50\n",
      "25391/25391 [==============================] - 213s 8ms/step - loss: 0.6903 - binary_accuracy: 0.5322 - val_loss: 0.6917 - val_binary_accuracy: 0.5226\n",
      "Epoch 45/50\n",
      "25391/25391 [==============================] - 210s 8ms/step - loss: 0.6903 - binary_accuracy: 0.5320 - val_loss: 0.6918 - val_binary_accuracy: 0.5206\n",
      "Epoch 46/50\n",
      "25391/25391 [==============================] - 210s 8ms/step - loss: 0.6903 - binary_accuracy: 0.5321 - val_loss: 0.6916 - val_binary_accuracy: 0.5219\n",
      "Epoch 47/50\n",
      "25391/25391 [==============================] - 210s 8ms/step - loss: 0.6903 - binary_accuracy: 0.5319 - val_loss: 0.6915 - val_binary_accuracy: 0.5230\n",
      "Epoch 48/50\n",
      "25391/25391 [==============================] - 206s 8ms/step - loss: 0.6903 - binary_accuracy: 0.5321 - val_loss: 0.6918 - val_binary_accuracy: 0.5206\n",
      "Epoch 49/50\n",
      "25391/25391 [==============================] - 197s 8ms/step - loss: 0.6902 - binary_accuracy: 0.5322 - val_loss: 0.6918 - val_binary_accuracy: 0.5205\n",
      "Epoch 50/50\n",
      "25391/25391 [==============================] - 165s 6ms/step - loss: 0.6903 - binary_accuracy: 0.5320 - val_loss: 0.6916 - val_binary_accuracy: 0.5219\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "learning_rate = 0.001  # Learning rate\n",
    "epochs = 50  # Number of training epochs\n",
    "es_patience = 10  # Patience for early stopping\n",
    "batch_size = 256  # Batch size\n",
    "\n",
    "# Data loaders\n",
    "loader_tr = BatchLoader(data_tr_fs, batch_size=batch_size, epochs=epochs)\n",
    "loader_va = BatchLoader(data_va_fs, batch_size=batch_size)\n",
    "loader_te = BatchLoader(data_te_fs, batch_size=batch_size)\n",
    "\n",
    "# Build model\n",
    "class Net_1_7(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(13, activation='relu')\n",
    "        self.pool1 = GlobalAvgPool()\n",
    "        self.dense = Dense(d.n_labels, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        # x.shape is [n_batches, 5, n_ features]\n",
    "        # a.shape is [n_batches, 5, 5]\n",
    "\n",
    "        x = self.conv1([x, a])\n",
    "        # x.shape is [n_batches, 5, channels] where I have set channels = features (20)\n",
    "\n",
    "        x = self.pool1(x)\n",
    "        # x.shape is [n_batches, channels]\n",
    "\n",
    "        x = self.dense(x)\n",
    "        # output.shape is [n_batches, 1]\n",
    "        \n",
    "        return x\n",
    "\n",
    "model_1_7 = Net_1_7()\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "loss_fn = BinaryCrossentropy()\n",
    "model_1_7.compile(optimizer=optimizer, loss=loss_fn, metrics=['binary_accuracy'])\n",
    "\n",
    "fit_log_1_7 = model_1_7.fit(loader_tr.load(), steps_per_epoch=loader_tr.steps_per_epoch, epochs=epochs, validation_data=loader_va.load(), validation_steps=loader_va.steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "epochs = list(range(1,len(fit_log_1_7.history['binary_accuracy'])+1))\n",
    "training_accuracy = fit_log_1_7.history['binary_accuracy']\n",
    "validation_accuracy = fit_log_1_7.history['val_binary_accuracy']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=training_accuracy,\n",
    "    mode='lines',\n",
    "    name='Training'))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=validation_accuracy,\n",
    "    mode='lines',\n",
    "    name='Validation'))\n",
    "fig.update_layout(\n",
    "    template='none',\n",
    "    xaxis_title='Epochs',\n",
    "    yaxis_title=\"Accuracy\")\n",
    "fig.update_xaxes(tick0=0, dtick=1)\n",
    "# fig.update_yaxes(range=[0.5,1])\n",
    "# fig.show()\n",
    "fig.write_image(f'../images/model_1_7_accuracy.png', scale=5)\n",
    "pd.DataFrame({'epoch': epochs, 'training_accuracy':training_accuracy, 'validation_accuracy':validation_accuracy}).to_csv('../images/model_1_7_accuracy.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1.8 Hyperparameter Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nick_\\miniconda3\\envs\\tf\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'DotaV1' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "25391/25391 [==============================] - 233s 9ms/step - loss: 0.6916 - binary_accuracy: 0.5241 - val_loss: 0.6907 - val_binary_accuracy: 0.5300\n",
      "Epoch 2/40\n",
      "25391/25391 [==============================] - 184s 7ms/step - loss: 0.6909 - binary_accuracy: 0.5292 - val_loss: 0.6905 - val_binary_accuracy: 0.5311\n",
      "Epoch 3/40\n",
      "25391/25391 [==============================] - 189s 7ms/step - loss: 0.6908 - binary_accuracy: 0.5298 - val_loss: 0.6908 - val_binary_accuracy: 0.5295\n",
      "Epoch 4/40\n",
      "25391/25391 [==============================] - 187s 7ms/step - loss: 0.6907 - binary_accuracy: 0.5303 - val_loss: 0.6903 - val_binary_accuracy: 0.5322\n",
      "Epoch 5/40\n",
      "25391/25391 [==============================] - ETA: 0s - loss: 0.6906 - binary_accuracy: 0.5310"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "learning_rate = 0.001  # Learning rate\n",
    "epochs = 40  # Number of training epochs\n",
    "es_patience = 10  # Patience for early stopping\n",
    "batch_size = 256  # Batch size\n",
    "\n",
    "# Data loaders\n",
    "loader_tr = BatchLoader(data_tr, batch_size=batch_size, epochs=epochs)\n",
    "loader_va = BatchLoader(data_va, batch_size=batch_size)\n",
    "loader_te = BatchLoader(data_te, batch_size=batch_size)\n",
    "\n",
    "# Build model\n",
    "class Net_1_8(Model):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(channels, activation='relu')\n",
    "        self.pool1 = GlobalAvgPool()\n",
    "        self.dense = Dense(d.n_labels, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        # x.shape is [n_batches, 5, n_ features]\n",
    "        # a.shape is [n_batches, 5, 5]\n",
    "\n",
    "        x = self.conv1([x, a])\n",
    "        # x.shape is [n_batches, 5, channels] where I have set channels = features (20)\n",
    "\n",
    "        x = self.pool1(x)\n",
    "        # x.shape is [n_batches, channels]\n",
    "\n",
    "        x = self.dense(x)\n",
    "        # output.shape is [n_batches, 1]\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Loop through range of num channels hyperparameter\n",
    "channels = [5,10,15,19,25]\n",
    "for i, channel in enumerate(channels):\n",
    "    # Compile and train model\n",
    "    model_1_8 = Net_1_8(channel)\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    loss_fn = BinaryCrossentropy()\n",
    "    model_1_8.compile(optimizer=optimizer, loss=loss_fn, metrics=['binary_accuracy'])\n",
    "    fit_log_1_8 = model_1_8.fit(loader_tr.load(), steps_per_epoch=loader_tr.steps_per_epoch, epochs=epochs, validation_data=loader_va.load(), validation_steps=loader_va.steps_per_epoch)\n",
    "\n",
    "    # Save training and validation results\n",
    "    epochs = list(range(1,len(fit_log_1_8.history['binary_accuracy'])+1))\n",
    "    training_accuracy = fit_log_1_8.history['binary_accuracy']\n",
    "    validation_accuracy = fit_log_1_8.history['val_binary_accuracy']\n",
    "    pd.DataFrame({'epoch': epochs, 'training_accuracy':training_accuracy, 'validation_accuracy':validation_accuracy}).to_csv(f'../images/model_1_8_{i+1}_accuracy.csv', index=False)\n",
    "\n",
    "    # Pickle model and training+validation log\n",
    "    filehandler = open(f'../models/fit_log_1_8_{i}.pkl','wb')\n",
    "    pickle.dump(fit_log_1_8, filehandler)\n",
    "    filehandler = open(f'../models/model_1_8_{i}.pkl','wb')\n",
    "    pickle.dump(model_1_8, filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1.9 MMR ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMEMBER to choose optimal channels!\n",
    "\n",
    "# Configuration\n",
    "learning_rate = 0.001  # Learning rate\n",
    "epochs = 50  # Number of training epochs\n",
    "es_patience = 10  # Patience for early stopping\n",
    "batch_size = 256  # Batch size\n",
    "\n",
    "# Build model\n",
    "class Net_1_9(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(19, activation='relu')\n",
    "        self.pool1 = GlobalAvgPool()\n",
    "        self.dense = Dense(d.n_labels, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        # x.shape is [n_batches, 5, n_ features]\n",
    "        # a.shape is [n_batches, 5, 5]\n",
    "\n",
    "        x = self.conv1([x, a])\n",
    "        # x.shape is [n_batches, 5, channels] where I have set channels = features (20)\n",
    "\n",
    "        x = self.pool1(x)\n",
    "        # x.shape is [n_batches, channels]\n",
    "\n",
    "        x = self.dense(x)\n",
    "        # output.shape is [n_batches, 1]\n",
    "        \n",
    "        return x\n",
    "\n",
    "mmrs = [1,2,3,4,5,6]\n",
    "\n",
    "for group in mmrs:\n",
    "    # Filter data for current mmr group\n",
    "    filt = df_filters['filt_std'].values & df_filters[f'filt_mmr_{group}'].values\n",
    "    step = 50000\n",
    "    filt_vals = []\n",
    "    for i in range(0,int(np.ceil(len(filt)/step))):\n",
    "        start = i*step\n",
    "        end = start+step\n",
    "        filt_vals = np.append(filt_vals, filt[start:end])\n",
    "        filt_vals = np.append(filt_vals, filt[start:end])\n",
    "\n",
    "    # Get indices of True values in filters\n",
    "    filt_idx = [i for i, x in enumerate(filt_vals) if x]\n",
    "\n",
    "    # Select subset of graphs\n",
    "    graphs_filt_mmr = graphs[filt_idx]\n",
    "\n",
    "    # Train/valid/test split\n",
    "    d = graphs_filt_mmr\n",
    "    np.random.seed(10)\n",
    "    idxs = np.random.permutation(len(d))\n",
    "    split_va, split_te = int(0.7 * len(d)), int(len(d)) #70% training, 30% validation\n",
    "    idx_tr, idx_va, idx_te = np.split(idxs, [split_va, split_te])\n",
    "    data_tr = d[idx_tr]\n",
    "    data_va = d[idx_va]\n",
    "\n",
    "    # Data loaders\n",
    "    loader_tr = BatchLoader(data_tr, batch_size=batch_size, epochs=epochs)\n",
    "    loader_va = BatchLoader(data_va, batch_size=batch_size)\n",
    "\n",
    "    # Compile and train model\n",
    "    model_1_9 = Net_1_9()\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    loss_fn = BinaryCrossentropy()\n",
    "    model_1_9.compile(optimizer=optimizer, loss=loss_fn, metrics=['binary_accuracy'])\n",
    "    fit_log_1_9 = model_1_9.fit(loader_tr.load(), steps_per_epoch=loader_tr.steps_per_epoch, epochs=epochs, validation_data=loader_va.load(), validation_steps=loader_va.steps_per_epoch)\n",
    "\n",
    "    # Save training and validation results\n",
    "    epochs = list(range(1,len(fit_log_1_9.history['binary_accuracy'])+1))\n",
    "    training_accuracy = fit_log_1_9.history['binary_accuracy']\n",
    "    validation_accuracy = fit_log_1_9.history['val_binary_accuracy']\n",
    "    pd.DataFrame({'epoch': epochs, 'training_accuracy':training_accuracy, 'validation_accuracy':validation_accuracy}).to_csv(f'../images/model_1_9_{group}_accuracy.csv', index=False)\n",
    "\n",
    "    # Pickle model and training+validation log\n",
    "    filehandler = open(f'../models/fit_log_1_9_{i}.pkl','wb')\n",
    "    pickle.dump(fit_log_1_9, filehandler)\n",
    "    filehandler = open(f'../models/model_1_9_{i}.pkl','wb')\n",
    "    pickle.dump(model_1_9, filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra useful code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: nan - binary_accuracy: 0.5090\n",
      "Test accuracy: 50.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nick_\\.virtualenvs\\dotaprediction-eZ2WDOkz\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'DotaV1' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(loader_te.load(), steps=loader_te.steps_per_epoch)\n",
    "print(f\"Test accuracy: {np.round(loss[1],4)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 1ms/step - loss: nan - binary_accuracy: 0.5800\n",
      "Test accuracy: 57.99999999999999%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nick_\\.virtualenvs\\dotaprediction-eZ2WDOkz\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'DotaV1' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    }
   ],
   "source": [
    "loader_single = BatchLoader(data_va, batch_size=128)\n",
    "loss = model.evaluate(loader_single.load(), steps=loader_single.steps_per_epoch)\n",
    "print(f\"Validation accuracy: {np.round(loss[1],4)*100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aead6205437b837a6f51f1a5578747fd76aee053b7788bc0930d4c5b4657d24d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
